import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import re
import streamlit as st
import plotly.graph_objects as go # [æ–°å¢] ç”¨äºæ¸²æŸ“ä»ªè¡¨ç›˜

# ==================== 1. å…¨å±€é…ç½®ä¸å¸¸é‡ ====================

# [V202] å…è´£å£°æ˜ (å…¨å±€å…±äº«)
CUSTOM_DISCLAIMER = "Disclaimer: Estimates (AVM) for reference only. Not certified valuations. Source: URA/Huttons. No warranty on accuracy."

# [V202] æ ‡å‡†åˆ—åæ˜ å°„ (ç»Ÿä¸€æ•°æ®æ¸…æ´—å£å¾„)
COLUMN_RENAME_MAP = {
    'Transacted Price ($)': 'Sale Price',
    'Area (SQFT)': 'Area (sqft)',
    'Unit Price ($ psf)': 'Unit Price ($ psf)',
    'Unit Price ($ psm)': 'Unit Price ($ psm)',
    'Sale Date': 'Sale Date',
    'Bedroom Type': 'Type',   
    'No. of Bedroom': 'Type', 
    'Tenure': 'Tenure',
    'Lease Commencement Date': 'Tenure From',
    'Tenure Start Date': 'Tenure From',
    'Property Type': 'Sub Type',
    'Building Type': 'Sub Type'
}

try:
    AGENT_PROFILE = dict(st.secrets["agent"])
except Exception:
    AGENT_PROFILE = {
        "Name": "Henry GUO",
        "Title": "Associate District Director",
        "Company": "Huttons Asia Pte Ltd",
        "License": "L3008899K",
        "RES_No": "R059451F", 
        "Mobile": "+65 8808 6086",
        "Email": "henry.guo@huttons.com"
    }

try:
    project_config = dict(st.secrets["projects"])
    cleaned_config = {k: (None if v == "None" else v) for k, v in project_config.items()}
    PROJECTS = cleaned_config
except Exception:
    PROJECTS = {
        "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None,
    }

# ==================== 2. é€šç”¨æ ¼å¼åŒ–å·¥å…· ====================

def natural_key(text):
    return [int(c) if c.isdigit() else c.lower() for c in re.split(r'(\d+)', str(text))]

def format_currency(val):
    try: return f"${val:,.0f}"
    except: return val

# [V202] æå–ä¸ºç‹¬ç«‹å‡½æ•°ï¼Œä¾› load_data å’Œå„ Tab ä½¿ç”¨
def format_unit(floor, stack):
    try:
        # å°è¯•è½¬æ¢ä¸ºæ•°å­—ä»¥å»é™¤å‰å¯¼é›¶æˆ–å¤„ç†æµ®ç‚¹
        f_num = int(float(floor))
        s_str = str(stack).strip()
        # Stack å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œè¡¥é½2ä½ï¼›å¦‚æœæ˜¯ 10A è¿™ç§ï¼Œä¿æŒåŸæ ·
        s_fmt = s_str.zfill(2) if s_str.isdigit() else s_str
        return f"#{f_num:02d}-{s_fmt}"
    except:
        # å‡ºé”™æ—¶å›é€€åˆ°åŸå§‹å­—ç¬¦ä¸²æ‹¼æ¥
        return f"#{floor}-{stack}"

# [V202] æ–°å¢è„±æ•æ ¼å¼åŒ–
def format_unit_masked(floor):
    try:
        f_num = int(float(floor))
        return f"#{f_num:02d}-XX"
    except:
        return f"#{floor}-XX"

# ==================== 3. æ•°æ®åŠ è½½ä¸æ¸…æ´— ====================

@st.cache_data(ttl=300)
def load_data(file_or_url):
    try:
        if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
        try:
            df_temp = pd.read_csv(file_or_url, header=None, nrows=20)
            header_row = -1
            for i, row in df_temp.iterrows():
                row_str = row.astype(str).str.cat(sep=',')
                if "Sale Date" in row_str or "BLK" in row_str:
                    header_row = i; break
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url, header=header_row if header_row != -1 else 0)
        except:
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url)

        df.columns = df.columns.str.strip()
        
        # [V202] ä½¿ç”¨ç»Ÿä¸€æ˜ å°„æ¸…æ´—åˆ—å (å¯é€‰ï¼Œè¿™é‡Œå…ˆä¿ç•™æ‚¨çš„åŸå§‹é€»è¾‘ï¼Œé¿å…æ”¹åŠ¨å¤ªå¤§)
        # df.rename(columns=COLUMN_RENAME_MAP, inplace=True) 
        
        for col in ['Sale Price', 'Sale PSF', 'Area (sqft)']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'Sale Date' in df.columns:
            df['Sale Date'] = pd.to_datetime(df['Sale Date'], errors='coerce')
            df['Sale Year'] = df['Sale Date'].dt.year
            df['Date_Ordinal'] = df['Sale Date'].map(datetime.toordinal)

        if 'BLK' in df.columns: df['BLK'] = df['BLK'].astype(str).str.strip()
        if 'Stack' in df.columns: df['Stack'] = df['Stack'].astype(str).str.strip()
        if 'Floor' in df.columns: df['Floor_Num'] = pd.to_numeric(df['Floor'], errors='coerce')

        if 'Stack' in df.columns and 'Floor_Num' in df.columns:
            # [V202] ä½¿ç”¨ä¸Šæ–¹å®šä¹‰çš„å…¨å±€å‡½æ•°
            df['Unit'] = df.apply(lambda row: format_unit(row['Floor_Num'], row['Stack']), axis=1)
            df['Unit_ID'] = df['BLK'].astype(str) + "-" + df['Stack'].astype(str) + "-" + df['Floor_Num'].astype(str)
        return df
    except Exception as e: return None

def auto_categorize(df, method):
    if method == "æŒ‰å§å®¤æ•°é‡ (Bedroom Type)":
        target_cols = ['Bedroom Type', 'Bedroom_Type', 'Bedrooms', 'Type']
        found = next((c for c in df.columns if c in target_cols or 'Bedroom' in c), None)
        return df[found].astype(str).str.strip().str.upper() if found else pd.Series(["Unknown"] * len(df))
    elif method == "æŒ‰æ¥¼åº§ (Block)": return df['BLK']
    else: return df['Area (sqft)'].apply(lambda x: "Small" if x<800 else "Medium" if x<1200 else "Large" if x<1600 else "X-Large" if x<2500 else "Giant")

def mark_penthouse(df):
    if 'Area (sqft)' not in df.columns or 'Category' not in df.columns: return pd.Series([False] * len(df))
    medians = df.groupby('Category')['Area (sqft)'].median()
    return df.apply(lambda row: row['Area (sqft)'] > (medians.get(row['Category'], 0) * 1.4), axis=1)

# ==================== 4. ä¸šåŠ¡é€»è¾‘ä¸ç®—æ³• ====================

def detect_block_step(blk_df):
    if blk_df.empty: return 1
    unique_stacks = blk_df['Stack'].unique()
    if len(unique_stacks) == 0: return 1
    votes_simplex = 0
    votes_maisonette = 0
    for stack in unique_stacks:
        stack_df = blk_df[blk_df['Stack'] == stack]
        floors = sorted(stack_df['Floor_Num'].dropna().unique())
        if len(floors) < 2: continue
        has_odd = any(f % 2 != 0 for f in floors)
        has_even = any(f % 2 == 0 for f in floors)
        if (has_odd and not has_even) or (not has_odd and has_even):
            votes_maisonette += 1
        else:
            votes_simplex += 1
    if votes_maisonette > votes_simplex: return 2
    else: return 1

def get_stack_start_floor(stack_df, block_min_f, step):
    if step == 1: return block_min_f
    floors = sorted(stack_df['Floor_Num'].dropna().unique())
    if not floors: return block_min_f
    odd_count = sum(1 for f in floors if f % 2 != 0)
    even_count = sum(1 for f in floors if f % 2 == 0)
    if odd_count > even_count:
        return block_min_f if block_min_f % 2 != 0 else block_min_f + 1
    else:
        return block_min_f if block_min_f % 2 == 0 else block_min_f + 1

def estimate_inventory(df, category_col='Category'):
    if 'BLK' not in df.columns or 'Floor_Num' not in df.columns: return {}
    if 'Stack' not in df.columns:
        inv_map = {}
        for cat in df[category_col].unique():
            inv_map[cat] = len(df[df[category_col] == cat])
        return inv_map

    df = df.dropna(subset=['Floor_Num']).copy()
    final_totals = {cat: 0 for cat in df[category_col].unique()}
    unique_blocks = df['BLK'].unique()
    
    for blk in unique_blocks:
        blk_df = df[df['BLK'] == blk]
        step = detect_block_step(blk_df)
        min_f = int(blk_df['Floor_Num'].min())
        max_f = int(blk_df['Floor_Num'].max())
        if min_f < 1: min_f = 1
        
        unique_stacks = blk_df['Stack'].unique()
        for stack in unique_stacks:
            stack_df = blk_df[blk_df['Stack'] == stack]
            if not stack_df.empty:
                dominant_cat = stack_df[category_col].mode()[0]
                start_f = get_stack_start_floor(stack_df, min_f, step)
                theoretical_floors = range(start_f, max_f + 1, step)
                count_per_stack = len(theoretical_floors)
                final_totals[dominant_cat] = final_totals.get(dominant_cat, 0) + count_per_stack

    observed_counts = df.groupby(category_col)['Unit_ID'].nunique().to_dict()
    for cat in final_totals:
        if final_totals[cat] < observed_counts.get(cat, 0):
            final_totals[cat] = observed_counts.get(cat, 0)
            
    return final_totals

def get_dynamic_floor_premium(df, category):
    # (ä¿æŒåŸæ ·...)
    cat_df = df[df['Category'] == category].copy()
    if cat_df.empty: return 0.005
    recent_limit = cat_df['Sale Date'].max() - timedelta(days=365*5)
    recent_df = cat_df[cat_df['Sale Date'] >= recent_limit]
    grouped = recent_df.groupby(['BLK', 'Stack'])
    rates = []
    for _, group in grouped:
        if len(group) < 2: continue
        recs = group.to_dict('records')
        for i in range(len(recs)):
            for j in range(i + 1, len(recs)):
                r1, r2 = recs[i], recs[j]
                if abs((r1['Sale Date'] - r2['Sale Date']).days) > 540: continue
                floor_diff = r1['Floor_Num'] - r2['Floor_Num']
                if floor_diff == 0: continue
                if r1['Floor_Num'] > r2['Floor_Num']: high, low, f_delta = r1, r2, floor_diff
                else: high, low, f_delta = r2, r1, -floor_diff
                rate = ((high['Sale PSF'] - low['Sale PSF']) / low['Sale PSF']) / f_delta
                if -0.005 < rate < 0.03: rates.append(rate)
    if len(rates) >= 3:
        fitted_rate = float(np.median(rates))
        return max(0.001, min(0.015, fitted_rate))
    else:
        return 0.005

def calculate_ssd_status(purchase_date):
    # (ä¿æŒåŸæ ·...)
    now, p_dt = datetime.now(), pd.to_datetime(purchase_date)
    held_years = (now - p_dt).days / 365.25
    rate, emoji, text = 0.0, "ğŸŸ¢", "SSD Free"
    if p_dt >= datetime(2025, 7, 4):
        if held_years < 1: rate, emoji, text = 0.16, "ğŸ”´", "SSD 16%"
        elif held_years < 2: rate, emoji, text = 0.12, "ğŸ”´", "SSD 12%"
        elif held_years < 3: rate, emoji, text = 0.08, "ğŸ”´", "SSD 8%"
        elif held_years < 4: rate, emoji, text = 0.04, "ğŸ”´", "SSD 4%"
    elif p_dt >= datetime(2017, 3, 11):
        if held_years < 1: rate, emoji, text = 0.12, "ğŸ”´", "SSD 12%"
        elif held_years < 2: rate, emoji, text = 0.08, "ğŸ”´", "SSD 8%"
        elif held_years < 3: rate, emoji, text = 0.04, "ğŸ”´", "SSD 4%"
    return rate, emoji, text

def get_market_trend_model(df):
    # (ä¿æŒåŸæ ·...)
    df_clean = df.dropna(subset=['Sale PSF', 'Date_Ordinal']).copy()
    if len(df_clean) < 10: return None, 0 
    q1 = df_clean['Sale PSF'].quantile(0.10)
    q3 = df_clean['Sale PSF'].quantile(0.90)
    df_clean = df_clean[(df_clean['Sale PSF'] >= q1) & (df_clean['Sale PSF'] <= q3)]
    x = df_clean['Date_Ordinal'].values
    y = df_clean['Sale PSF'].values
    coeffs = np.polyfit(x, y, 1) 
    trend_func = np.poly1d(coeffs)
    y_pred = trend_func(x)
    ss_res = np.sum((y - y_pred) ** 2)
    ss_tot = np.sum((y - np.mean(y)) ** 2)
    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
    return trend_func, r2

# ==================== 5. å…±äº«å›¾è¡¨ç»„ä»¶ ====================

# [V202] æå–è‡ª tab3_avm.pyï¼Œä¾›å¤šå¤„å¤ç”¨
def render_gauge(est_psf, font_size=12):
    range_min = est_psf * 0.90
    range_max = est_psf * 1.10
    axis_min = est_psf * 0.80
    axis_max = est_psf * 1.20
        
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = est_psf,
        number = {'suffix': " psf", 'font': {'size': 18}}, 
        domain = {'x': [0, 1], 'y': [0, 1]},
        gauge = {
            'axis': {
                'range': [axis_min, axis_max], 
                'tickwidth': 1, 
                'tickcolor': "darkblue",
                'tickmode': 'array',
                'tickvals': [axis_min, est_psf, axis_max],
                'ticktext': [f"{int(axis_min)}", f"{int(est_psf)}", f"{int(axis_max)}"]
            },
            'bar': {'thickness': 0}, 
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "#e5e7eb",
            'steps': [
                {'range': [axis_min, range_min], 'color': "#f3f4f6"},
                {'range': [range_min, range_max], 'color': "#2563eb"},
                {'range': [range_max, axis_max], 'color': "#f3f4f6"}
            ],
            'threshold': {
                'line': {'color': "#dc2626", 'width': 3},
                'thickness': 0.8,
                'value': est_psf
            }
        }
    ))
    fig.update_layout(
        height=150, 
        margin=dict(l=20, r=20, t=10, b=10),
        paper_bgcolor="rgba(0,0,0,0)",
        font={'family': "Arial", 'size': 11}
    )
    return fig

# ... (Calculate AVM å’Œ Resale Metrics ä¿æŒåŸæ ·ï¼Œæœªæ”¹åŠ¨)
def calculate_avm(df, blk, stack, floor):
    # (ä»£ç çœç•¥ï¼Œä¿æŒæ‚¨åŸæ–‡ä»¶çš„å†…å®¹ï¼Œæ­¤å¤„ä¸åšæ”¹åŠ¨)
    # ... è¯·ç¡®ä¿ä¿ç•™åŸæ–‡ä»¶åç»­çš„ calculate_avm ä»£ç  ...
    # ä¸ºèŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œå‡å®šæ‚¨åªæ›¿æ¢ä¸ŠåŠéƒ¨åˆ†ï¼Œæˆ–è€…æ‚¨å¤åˆ¶åŸ utils.py çš„ååŠéƒ¨åˆ†æ¥åœ¨ render_gauge åé¢
    # å¦‚æœæ‚¨ç›´æ¥å…¨é€‰è¦†ç›–ï¼Œè¯·åŠ¡å¿…æŠŠåŸ utils.py æœ€åçš„ calculate_avm å’Œ calculate_resale_metrics æ‹·å›æ¥
    # æˆ–è€…è®©æˆ‘çŸ¥é“ï¼Œæˆ‘ä¸ºæ‚¨æä¾›åŒ…å«æ‰€æœ‰å†…å®¹çš„å®Œæ•´ä»£ç ã€‚
    
    # âš ï¸ ä¸´æ—¶å ä½ï¼Œè¯·æ›¿æ¢ä¸ºåŸä»£ç 
    target_unit = df[(df['BLK'] == blk) & (df['Stack'] == stack) & (df['Floor_Num'] == floor)]
    # ... (åŸæœ‰é€»è¾‘)
    return None, None, None, None, None, pd.DataFrame(), None # å ä½

def calculate_resale_metrics(df):
    # (åŸæœ‰é€»è¾‘)
    return pd.DataFrame()
