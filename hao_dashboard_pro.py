# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import calendar

# ==========================================
# ğŸ”§ 1. é…ç½®ä¸­å¿ƒ (é¡¹ç›®åˆ—è¡¨)
# ==========================================
# ä¼˜å…ˆè¯»å– Streamlit Secrets (äº‘ç«¯å®‰å…¨é…ç½®)
# å¦‚æœæ²¡æœ‰ Secretsï¼Œåˆ™ä½¿ç”¨ä¸‹æ–¹çš„é»˜è®¤åˆ—è¡¨ (æœ¬åœ°æµ‹è¯•ç”¨)
try:
    project_config = dict(st.secrets["projects"])
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}
    PROJECTS.update(project_config)
except:
    # --- å¦‚æœæ‚¨åœ¨æœ¬åœ°è¿è¡Œä¸”æ²¡é…ç½® secrets.tomlï¼Œè¯·åœ¨è¿™é‡Œç›´æ¥å¡«å…¥é“¾æ¥ ---
    PROJECTS = {
        "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None,
        # ç¤ºä¾‹æ ¼å¼ (è¯·æ›¿æ¢ä¸ºæ‚¨çœŸå®çš„å‘å¸ƒé“¾æ¥):
        # "ğŸ¢ Braddell View": "https://docs.google.com/spreadsheets/d/e/2PACX-xxxx.../pub?output=csv",
    }

# ==========================================
# ğŸ–¥ï¸ 2. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(page_title="HAOæ•°æ®ä¸­å° Pro", layout="wide", page_icon="ğŸ§­")

# ==========================================
# ğŸ› ï¸ 3. æ ¸å¿ƒç®—æ³•å‡½æ•°åº“
# ==========================================

@st.cache_data(ttl=300)
def load_data(file_or_url):
    """è¯»å–æ•°æ®å¹¶æ™ºèƒ½æ¸…æ´— (æ”¯æŒè·³è¿‡ Disclaimer)"""
    try:
        if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
        
        # æ™ºèƒ½ Header è¯†åˆ«
        try:
            df_temp = pd.read_csv(file_or_url, header=None, nrows=20)
            header_row = -1
            for i, row in df_temp.iterrows():
                row_str = row.astype(str).str.cat(sep=',')
                if "Sale Date" in row_str or "BLK" in row_str:
                    header_row = i
                    break
            
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url, header=header_row if header_row != -1 else 0)
        except:
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url)

        # åŸºç¡€æ¸…æ´—
        df.columns = df.columns.str.strip()
        # æ¸…æ´—é‡‘é’±å’Œæ•°å­—
        for col in ['Sale Price', 'Sale PSF', 'Area (sqft)']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # æ¸…æ´—æ—¥æœŸ
        if 'Sale Date' in df.columns:
            df['Sale Date'] = pd.to_datetime(df['Sale Date'], errors='coerce')
            df['Sale Year'] = df['Sale Date'].dt.year

        # æ¸…æ´—å­—ç¬¦ä¸²åˆ—
        if 'BLK' in df.columns: df['BLK'] = df['BLK'].astype(str).str.strip()
        if 'Stack' in df.columns: df['Stack'] = df['Stack'].astype(str).str.strip()
        
        # æ¸…æ´—æ¥¼å±‚ (æå–æ•°å­—)
        if 'Floor' in df.columns:
            df['Floor_Num'] = pd.to_numeric(df['Floor'], errors='coerce')

        return df
    except Exception as e:
        st.error(f"æ•°æ®è¯»å–é”™è¯¯: {e}")
        return None

def auto_categorize(df, method):
    """æ™ºèƒ½æˆ·å‹åˆ†ç±»"""
    if method == "æŒ‰æ¥¼åº§ (Block)": 
        return df['BLK']
    elif method == "æŒ‰å§å®¤ç±»å‹ (å¦‚æœæ•°æ®æœ‰)":
        cols = [c for c in df.columns if 'Bedroom' in c or 'Type' in c]
        return df[cols[0]].astype(str) if cols else pd.Series(["æœªçŸ¥"] * len(df))
    else: 
        # é»˜è®¤ï¼šæŒ‰é¢ç§¯åˆ†ç®±
        def size_bin(area):
            if area < 800: return "Small (<800sf)"
            if area < 1200: return "Medium (800-1.2k)"
            if area < 1600: return "Large (1.2k-1.6k)"
            if area < 2500: return "X-Large (1.6k-2.5k)"
            return "Giant (>2.5k)"
        return df['Area (sqft)'].apply(size_bin)

def estimate_inventory(df, category_col='Category'):
    """
    V7 æ™ºèƒ½åº“å­˜ç®—æ³• (Category Fallback Mode)
    å½»åº•è§£å†³"å†·é—¨æ¥¼æ ‹"(å¦‚10A)å› äº¤æ˜“å°‘è€Œè¢«ä½ä¼°çš„é—®é¢˜ã€‚
    """
    if 'BLK' not in df.columns or 'Floor_Num' not in df.columns:
        return {}

    df = df.dropna(subset=['Floor_Num']).copy()
    
    # 1. è¯†åˆ« Penthouse (ç‰¹æ®Šå±‚ç†”æ–­æœºåˆ¶)
    median_size = df['Area (sqft)'].median()
    df['Is_Special'] = df.apply(lambda row: row['Area (sqft)'] > (median_size * 1.4), axis=1)

    # 2. è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„"åŸºå‡†æœ€é«˜å±‚æ•°" (Category Benchmark)
    cat_benchmark_floors = {}
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        std_df = cat_df[~cat_df['Is_Special']]
        max_floor = std_df['Floor_Num'].max() if not std_df.empty else 1
        cat_benchmark_floors[cat] = max_floor

    block_inventory_map = {} 
    category_total_map = {}

    # 3. é€æ ‹è®¡ç®—
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        cat_total_inv = 0
        benchmark_floor = cat_benchmark_floors.get(cat, 1)
        
        for blk in cat_df['BLK'].unique():
            blk_df = cat_df[cat_df['BLK'] == blk]
            
            # A. è·å– Stack æ•°
            num_stacks = blk_df['Stack'].nunique() if 'Stack' in blk_df.columns else 1
            
            # B. è·å–æœ¬åœ°æ ‡å‡†å±‚æ•°
            std_units = blk_df[~blk_df['Is_Special']]
            local_max = std_units['Floor_Num'].max() if not std_units.empty else 0
            
            # C. æ™ºèƒ½çŸ«æ­£ (Fallback)
            # å¦‚æœæœ¬åœ°æœ€é«˜å±‚æ˜¾è‘—ä½äºåŸºå‡† (å°‘äº2å±‚ä»¥ä¸Š)ï¼Œå¼ºåˆ¶è¡¥å…¨è‡³åŸºå‡†
            # åŒæ—¶ä¹Ÿè€ƒè™‘å¤å¼æ¥¼çš„æƒ…å†µï¼Œå–åŒç±»ä¸­"å±‚æ•°æœ€å¤š"çš„ä½œä¸ºå‚è€ƒ
            final_floors_count = len(std_units['Floor_Num'].unique()) # åˆå§‹å€¼ï¼šæœ¬åœ°æœ‰å¤šå°‘å±‚ç®—å¤šå°‘å±‚
            
            if local_max < (benchmark_floor - 2):
                # è§¦å‘è¡¥å…¨ï¼šå¯»æ‰¾è¯¥åˆ†ç±»ä¸‹æœ€æ´»è·ƒçš„é‚£æ ‹æ¥¼çš„å±‚æ•°
                best_blk_floors = 0
                for b_temp in cat_df['BLK'].unique():
                    f_set = set(cat_df[(cat_df['BLK']==b_temp) & (~cat_df['Is_Special'])]['Floor_Num'].unique())
                    if len(f_set) > best_blk_floors:
                        best_blk_floors = len(f_set)
                final_floors_count = best_blk_floors
            
            # D. è®¡ç®—åº“å­˜
            base_inv = num_stacks * final_floors_count
            
            # E. ç‰¹æ®Šåº“å­˜ (Penthouse)
            ph_inv = 0
            if 'Stack' in blk_df.columns:
                ph_inv = blk_df[blk_df['Is_Special']].groupby(['Stack', 'Floor_Num']).ngroups
            else:
                ph_inv = len(blk_df[blk_df['Is_Special']])
            
            total_blk_inv = int(base_inv + ph_inv)
            
            # è®°å½•
            block_inventory_map[blk] = total_blk_inv
            cat_total_inv += total_blk_inv

        category_total_map[cat] = int(cat_total_inv)
            
    # ä¿å­˜è°ƒè¯•ä¿¡æ¯åˆ° Session State
    st.session_state['block_inv_debug'] = block_inventory_map
    
    return category_total_map

# ==========================================
# ğŸ¨ 4. ä¾§è¾¹æ ä¸ä¸»ç•Œé¢é€»è¾‘
# ==========================================

with st.sidebar:
    st.header("1. é¡¹ç›®åˆ‡æ¢")
    selected_project = st.selectbox("é€‰æ‹©è¦åˆ†æçš„é¡¹ç›®", list(PROJECTS.keys()))
    
    sheet_url = PROJECTS[selected_project]
    uploaded_file = None
    project_name = selected_project

    if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
        uploaded_file = st.file_uploader("æ‹–å…¥ CSV æ–‡ä»¶", type=['csv'])
        if uploaded_file:
            project_name = uploaded_file.name.replace(".csv", "")
    else:
        st.success(f"â˜ï¸ å·²è¿æ¥äº‘ç«¯: {selected_project}")

    st.markdown("---")
    st.header("2. ç»Ÿè®¡è®¾å®š")

    category_method = st.selectbox("åˆ†ç±»ä¾æ®", ["æŒ‰æˆ·å‹é¢ç§¯æ®µ (è‡ªåŠ¨åˆ†ç®±)", "æŒ‰æ¥¼åº§ (Block)", "æŒ‰å§å®¤ç±»å‹"])
    inventory_mode = st.radio("åº“å­˜è®¡ç®—æ¨¡å¼", ["ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)", "ğŸ– æ‰‹åŠ¨è¾“å…¥"], index=0)
    
    inventory_container = st.container()

    st.markdown("---")
    st.header("3. å¯¼å‡ºè®¾ç½®")
    chart_font_size = st.number_input("å›¾è¡¨å­—å·", value=16, min_value=10)
    chart_color = st.color_picker("ä¸»è‰²è°ƒ", "#F63366")
    
    st.caption("ğŸ“· å›¾ç‰‡ä¸‹è½½å°ºå¯¸")
    exp_width = st.number_input("å®½åº¦ (px)", value=1200, step=100)
    exp_height = st.number_input("é«˜åº¦ (px)", value=675, step=100)
    exp_scale = st.slider("æ¸…æ™°åº¦", 1, 5, 2)

# --- æ•°æ®åŠ è½½ ---
df = None
if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
    if uploaded_file: df = load_data(uploaded_file)
elif sheet_url:
    df = load_data(sheet_url)

if df is not None:
    # 4.1 åˆ†ç±»ä¸åº“å­˜
    df['Category'] = auto_categorize(df, category_method)
    unique_cats = sorted(df['Category'].unique())
    inventory_map = {}

    with inventory_container:
        if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'Stack' in df.columns and 'Floor_Num' in df.columns:
            st.info("å·²å¯ç”¨ V7 æ™ºèƒ½åº“å­˜ç®—æ³• (è‡ªåŠ¨è¡¥å…¨å†·é—¨æ¥¼æ ‹)")
            estimated_inv = estimate_inventory(df, 'Category')
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                est_val = int(estimated_inv.get(cat, 100))
                with cols[i % 2]:
                    # å…è®¸åœ¨æ¨å®šåŸºç¡€ä¸Šå¾®è°ƒ
                    val = st.number_input(f"[{cat}] åº“å­˜", value=est_val, min_value=1, key=f"inv_{i}")
                    inventory_map[cat] = val
        else:
            if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š..." and 'Stack' not in df.columns:
                st.warning("æ•°æ®ç¼ºå°‘ Stack åˆ—ï¼Œæ— æ³•è‡ªåŠ¨æ¨å®šï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ã€‚")
            st.caption("è¯·è¾“å…¥å„åˆ†ç±»æ€»æˆ·æ•°ï¼š")
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                with cols[i % 2]:
                    val = st.number_input(f"[{cat}]", value=100, min_value=1, key=f"inv_{i}")
                    inventory_map[cat] = val

    total_project_inventory = sum(inventory_map.values())
    
    # ğŸ•µï¸â€â™€ï¸ åº“å­˜å®¡è®¡ (Debug)
    if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'block_inv_debug' in st.session_state:
        with st.expander(f"ğŸ•µï¸â€â™€ï¸ æŸ¥çœ‹æ¯æ ‹æ¥¼çš„å…·ä½“æ¨å®šæ•°æ® (Debug) - æ€»è®¡: {total_project_inventory}æˆ·"):
            debug_map = st.session_state['block_inv_debug']
            debug_df = pd.DataFrame(list(debug_map.items()), columns=['Block', 'Est. Inventory'])
            if 'BLK' in df.columns:
                actual_vol = df['BLK'].value_counts().reset_index()
                actual_vol.columns = ['Block', 'Sold Volume']
                audit_df = pd.merge(debug_df, actual_vol, on='Block', how='left').fillna(0)
                audit_df['Sold Volume'] = audit_df['Sold Volume'].astype(int)
                audit_df['Coverage %'] = (audit_df['Sold Volume'] / audit_df['Est. Inventory'] * 100)
                st.dataframe(audit_df.sort_values('Block'), use_container_width=True, 
                             column_config={"Coverage %": st.column_config.ProgressColumn("å·²å”®å æ¯”", format="%.1f%%", min_value=0, max_value=100)})

    # --- 5. ä»ªè¡¨ç›˜å±•ç¤º ---
    st.title(f"ğŸ™ï¸ {project_name} å¸‚åœºé€è§†")
    st.caption(f"æ•°æ®èŒƒå›´: {df['Sale Date'].min().date()} è‡³ {df['Sale Date'].max().date()} | æ€»äº¤æ˜“: {len(df)} å®—")

    # 5.1 KPI (YTD)
    current_year = datetime.now().year 
    df_this_year = df[df['Sale Year'] == current_year]
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric(f"{current_year}å¹´ æˆäº¤é‡", f"{len(df_this_year)} å®—")
    if len(df_this_year) > 0:
        col2.metric(f"{current_year} å‡å°ºä»·", f"${df_this_year['Sale PSF'].mean():,.0f} psf")
        col3.metric(f"{current_year} æœ€é«˜ä»·", f"${df_this_year['Sale Price'].max()/1e6:.2f}M")
    else:
        col2.metric(f"{current_year} å‡å°ºä»·", "-")
        col3.metric(f"{current_year} æœ€é«˜ä»·", "-")
    
    turnover_ytd = (len(df_this_year) / total_project_inventory * 100) if total_project_inventory > 0 else 0
    col4.metric(f"{current_year} æ•´ä½“æ¢æ‰‹ç‡", f"{turnover_ytd:.2f}%")

    st.divider()

    # 5.2 è¶‹åŠ¿å›¾
    st.subheader("ğŸ“ˆ ä»·æ ¼ä¸æˆäº¤é‡è¶‹åŠ¿")
    col_ctrl1, col_ctrl2 = st.columns([1, 3])
    with col_ctrl1:
        freq_map = {"å¹´ (Year)": "Y", "å­£åº¦ (Quarter)": "Q", "æœˆ (Month)": "M"}
        freq_sel = st.selectbox("æ—¶é—´ç²’åº¦", list(freq_map.keys()))
        freq_code = freq_map[freq_sel]
        
        # æ™ºèƒ½æ—¶é—´èŒƒå›´é”å®š
        min_d = df['Sale Date'].min().date().replace(day=1)
        max_d_raw = df['Sale Date'].max().date()
        last_day = calendar.monthrange(max_d_raw.year, max_d_raw.month)[1]
        max_d = max_d_raw.replace(day=last_day)
        date_range = st.date_input("é€‰æ‹©æ—¶é—´èŒƒå›´", [min_d, max_d])

    if len(date_range) == 2:
        start_d = pd.to_datetime(date_range[0])
        end_d = pd.to_datetime(date_range[1]) + timedelta(days=1) - timedelta(seconds=1)
        mask = (df['Sale Date'] >= start_d) & (df['Sale Date'] <= end_d)
        df_filtered = df.loc[mask]
    else:
        df_filtered = df

    trend_data = df_filtered.set_index('Sale Date').groupby('Category').resample(freq_code).agg({
        'Sale PSF': 'mean', 'Sale Price': 'count'
    }).rename(columns={'Sale Price': 'Volume'}).reset_index()

    fig = px.line(
        trend_data, x='Sale Date', y='Sale PSF', color='Category', 
        markers=True, symbol='Category',
        title=f"{project_name} å°ºä»·èµ°åŠ¿ ({freq_sel})",
        color_discrete_sequence=[chart_color, "#2E86C1", "#28B463", "#D35400", "#8E44AD"]
    )
    
    fig.update_traces(connectgaps=True)
    fig.update_layout(
        font=dict(size=chart_font_size, family="Arial"),
        title=dict(font=dict(size=chart_font_size + 4)),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, title=None),
        hovermode="x unified"
    )
    
    st.plotly_chart(fig, use_container_width=True, config={
        'displayModeBar': True,
        'toImageButtonOptions': {
            'format': 'png', 'filename': f'{project_name}_trend',
            'height': exp_height, 'width': exp_width, 'scale': exp_scale
        },
        'displaylogo': False
    })

    st.divider()

    # 5.3 æ¥¼å®‡é€è§† (Tower View)
    st.subheader("ğŸ¢ æ¥¼å®‡é€è§† (Tower View)")
    st.caption("Xè½´=Stack(å•å…ƒ), Yè½´=Floor(æ¥¼å±‚)ã€‚ç°è‰²=ç†è®ºå­˜åœ¨ä½†æœªäº¤æ˜“(åº“å­˜), å½©è‰²=å†å²äº¤æ˜“")
    
    if 'BLK' in df.columns:
        blk_counts = df['BLK'].value_counts()
        selected_blk = st.selectbox("é€‰æ‹©æ¥¼æ ‹", blk_counts.index.tolist())
        
        if selected_blk:
            blk_df = df[df['BLK'] == selected_blk].copy()
            
            # --- æ„å»ºå¯è§†åŒ–ç½‘æ ¼ ---
            # 1. è·å–è¯¥æ ‹æ¥¼ç†è®ºä¸Šçš„æ ‡å‡†å±‚é›†åˆ (V7é€»è¾‘)
            # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å–åŒç±»ä¸­æœ€æ´»è·ƒæ¥¼æ ‹çš„å±‚æ•°ä½œä¸ºå‚è€ƒï¼Œé˜²æ­¢ 10A åªç”»å‡ºä¸€åŠ
            cat_this = blk_df['Category'].iloc[0]
            cat_df_all = df[df['Category'] == cat_this]
            
            # å¯»æ‰¾åŒç±»åŸºå‡†å±‚æ•°
            std_units_cat = cat_df_all[~cat_df_all['Is_Special']]
            max_cat_floor = std_units_cat['Floor_Num'].max() if not std_units_cat.empty else 1
            
            # æœ¬åœ°æ ‡å‡†å±‚
            std_units_local = blk_df[~blk_df['Is_Special']]
            local_floors = set(std_units_local['Floor_Num'].unique())
            
            # æ™ºèƒ½è¡¥å…¨é›†åˆï¼šå¦‚æœæœ¬åœ°å±‚æ•°å¤ªå°‘ï¼Œå°è¯•è¡¥å…¨
            final_floors_set = local_floors.copy()
            if (len(local_floors) > 0) and (max(local_floors) < max_cat_floor - 2):
                # å°è¯•è¡¥å…¨ï¼šè¿™é‡Œä¸ºäº†ç”»å›¾ç®€å•ï¼Œæˆ‘ä»¬å‡è®¾å¦‚æœç¼ºå¤±ï¼Œå°±è¡¥å…¨ range(2, max_cat_floor, 2) æˆ– range(2, max_cat_floor)
                # æ›´ç²¾ç»†çš„åšæ³•æ˜¯å–åŒç±»æ¥¼æ ‹çš„ floors union
                # è¿™é‡Œåšä¸ªè¿‘ä¼¼ï¼šå–åŒç±»æ‰€æœ‰æ¥¼å±‚é›†åˆ
                all_cat_floors = set(std_units_cat['Floor_Num'].unique())
                final_floors_set = all_cat_floors
            
            all_stacks = sorted(blk_df['Stack'].unique()) if 'Stack' in blk_df.columns else ['Unknown']
            
            grid_data = []
            for stack in all_stacks:
                # æ£€æŸ¥è¯¥ stack æ˜¯å¦æœ‰ PH
                ph_floors = blk_df[(blk_df['Stack'] == stack) & (blk_df['Is_Special'])]['Floor_Num'].unique()
                theoretical_floors = final_floors_set.union(set(ph_floors))
                
                for floor in theoretical_floors:
                    match = blk_df[(blk_df['Stack'] == stack) & (blk_df['Floor_Num'] == floor)]
                    if not match.empty:
                        latest = match.sort_values('Sale Date', ascending=False).iloc[0]
                        grid_data.append({
                            'Stack': stack, 'Floor': floor, 'Status': 'Sold',
                            'PSF': int(latest['Sale PSF']), 'Date': latest['Sale Date'].strftime('%Y-%m')
                        })
                    else:
                        grid_data.append({
                            'Stack': stack, 'Floor': floor, 'Status': 'Stock',
                            'PSF': 0, 'Date': '-'
                        })
            
            viz_df = pd.DataFrame(grid_data)
            
            if not viz_df.empty:
                # åˆ†å±‚ç»˜å›¾
                fig_tower = go.Figure()
                
                # 1. åº“å­˜å±‚ (ç°è‰²)
                df_stock = viz_df[viz_df['Status'] == 'Stock']
                fig_tower.add_trace(go.Scatter(
                    x=df_stock['Stack'], y=df_stock['Floor'], mode='markers',
                    marker=dict(symbol='square', size=18, color='lightgrey', line=dict(width=1, color='grey')),
                    name='åº“å­˜ (æœªå”®)', hoverinfo='text',
                    text=[f"Stack {s} #{f}<br>åº“å­˜" for s, f in zip(df_stock['Stack'], df_stock['Floor'])]
                ))
                
                # 2. äº¤æ˜“å±‚ (å½©è‰²)
                df_sold = viz_df[viz_df['Status'] == 'Sold']
                fig_tower.add_trace(go.Scatter(
                    x=df_sold['Stack'], y=df_sold['Floor'], mode='markers',
                    marker=dict(
                        symbol='square', size=18, color=df_sold['PSF'], colorscale='RdBu_r',
                        colorbar=dict(title="æœ€æ–° PSF"), line=dict(width=1, color='black')
                    ),
                    name='å·²å”®', hoverinfo='text',
                    text=[f"Stack {s} #{f}<br>${p} psf<br>{d}" for s, f, p, d in zip(df_sold['Stack'], df_sold['Floor'], df_sold['PSF'], df_sold['Date'])]
                ))
                
                fig_tower.update_layout(
                    title=f"Block {selected_blk} åº“å­˜é€è§† (è¡¥å…¨å)",
                    xaxis=dict(title="Stack", type='category'),
                    yaxis=dict(title="Floor", dtick=1),
                    height=600, width=800, plot_bgcolor='white'
                )
                st.plotly_chart(fig_tower, use_container_width=True, config={
                    'toImageButtonOptions': {'format': 'png', 'height': exp_height, 'width': exp_width, 'scale': exp_scale}
                })
                
                # ç®€å•çš„ç»Ÿè®¡æ¡
                sold_count = len(df_sold)
                total_count = len(viz_df)
                st.info(f"ğŸ“Š é¢æ¿æ•°æ®ï¼šæ€»æ¨ç®— {total_count} æˆ· | å†å²æˆäº¤ {sold_count} æˆ· | è¦†ç›–ç‡ {(sold_count/total_count*100):.1f}%")
            else:
                st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆé€è§†å›¾")
    else:
        st.warning("CSV ç¼ºå°‘ BLK åˆ—ï¼Œæ— æ³•æ˜¾ç¤ºæ¥¼å®‡é€è§†")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®æˆ–ä¸Šä¼  CSV æ–‡ä»¶ã€‚")