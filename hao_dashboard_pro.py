# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import calendar

# ==========================================
# ğŸ”§ å®‰å…¨é…ç½®ä¸­å¿ƒ (ä» Secrets è¯»å–)
# ==========================================
try:
    # å°è¯•ä» Streamlit Secrets è¯»å–é¡¹ç›®åˆ—è¡¨
    # dict() å°†å…¶è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸ï¼Œæ–¹ä¾¿åç»­æ“ä½œ
    project_config = dict(st.secrets["projects"])
    
    # å°†"æ‰‹åŠ¨ä¸Šä¼ "æ·»åŠ åˆ°é€‰é¡¹çš„æœ€å‰é¢
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}
    PROJECTS.update(project_config)
    
except FileNotFoundError:
    # å¦‚æœæ²¡æ‰¾åˆ° secrets (æ¯”å¦‚åˆšä¸‹è½½è¿˜æ²¡é…ç½®æ—¶)ï¼Œåªä¿ç•™æ‰‹åŠ¨ä¸Šä¼ 
    st.warning("âš ï¸ æœªæ£€æµ‹åˆ°äº‘ç«¯é…ç½®æ–‡ä»¶ (Secrets)ã€‚ä»…æ”¯æŒæ‰‹åŠ¨ä¸Šä¼ æ¨¡å¼ã€‚")
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}
except Exception as e:
    st.error(f"é…ç½®æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="HAOæ•°æ®ä¸­å° Pro", layout="wide", page_icon="ğŸ§­")

# --- 2. ä¾§è¾¹æ ï¼šé¡¹ç›®æ§åˆ¶å° ---
with st.sidebar:
    st.header("1. é¡¹ç›®åˆ‡æ¢")
    
    # é¡¹ç›®é€‰æ‹©å™¨
    selected_project = st.selectbox("é€‰æ‹©è¦åˆ†æçš„é¡¹ç›®", list(PROJECTS.keys()))
    
    sheet_url = PROJECTS[selected_project]
    uploaded_file = None
    project_name = selected_project

    # å¦‚æœé€‰äº†æ‰‹åŠ¨ä¸Šä¼ 
    if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
        uploaded_file = st.file_uploader("æ‹–å…¥äº¤æ˜“è®°å½• CSV", type=['csv'])
        if uploaded_file:
            project_name = uploaded_file.name.replace(".csv", "")
    else:
        st.success(f"å·²è¿æ¥äº‘ç«¯æ•°æ®æº: {selected_project}")

    st.markdown("---")
    st.header("2. ç»Ÿè®¡é€»è¾‘è®¾å®š")

    # åˆ†ç±»é€»è¾‘
    category_method = st.selectbox(
        "æˆ·å‹åˆ†ç±»ä¾æ®",
        ["æŒ‰æˆ·å‹é¢ç§¯æ®µ (è‡ªåŠ¨åˆ†ç®±)", "æŒ‰æ¥¼åº§ (Block)", "æŒ‰å§å®¤ç±»å‹ (å¦‚æœæ•°æ®æœ‰)"]
    )
    
    # åº“å­˜è®¡ç®—æ¨¡å¼
    inventory_mode = st.radio("åº“å­˜è®¡ç®—æ¨¡å¼", ["ğŸ¤– è‡ªåŠ¨æ¨å®š (åŸºäºStackæœ€é«˜æ¥¼å±‚)", "ğŸ– æ‰‹åŠ¨è¾“å…¥"], index=0)
    inventory_container = st.container() # å ä½ç¬¦

    st.markdown("---")
    st.header("3. å¯¼å‡º/æ˜¾ç¤ºè®¾ç½®")
    
    # å­—ä½“ä¸é¢œè‰²
    chart_font_size = st.number_input("å›¾è¡¨å­—å· (Font Size)", value=16, min_value=10, max_value=50)
    chart_color = st.color_picker("ä¸»è‰²è°ƒ", "#F63366")
    
    # å›¾ç‰‡å°ºå¯¸æ§åˆ¶
    st.subheader("ğŸ–¼ï¸ å›¾ç‰‡ä¸‹è½½å°ºå¯¸")
    exp_width = st.number_input("å›¾ç‰‡å®½åº¦ (px)", value=1200, step=100)
    exp_height = st.number_input("å›¾ç‰‡é«˜åº¦ (px)", value=675, step=100)
    exp_scale = st.slider("æ¸…æ™°åº¦å€æ•° (Scale)", 1, 5, 2)

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

@st.cache_data(ttl=300) # 5åˆ†é’Ÿç¼“å­˜ï¼Œç¡®ä¿æ•°æ®è¾ƒæ–°
def load_data(file_or_url):
    try:
        # å¤„ç†æ‰‹åŠ¨ä¸Šä¼ çš„æ–‡ä»¶æŒ‡é’ˆ
        if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
        
        # æ™ºèƒ½ Header è¯†åˆ« (è·³è¿‡ Disclaimer)
        try:
            # å…ˆè¯»å‰20è¡Œæ‰¾å…³é”®å­—
            df_temp = pd.read_csv(file_or_url, header=None, nrows=20)
            header_row = -1
            for i, row in df_temp.iterrows():
                row_str = row.astype(str).str.cat(sep=',')
                if "Sale Date" in row_str or "BLK" in row_str:
                    header_row = i
                    break
            
            # é‡ç½®æŒ‡é’ˆå¹¶è¯»å–
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url, header=header_row if header_row != -1 else 0)
        except:
            # å¦‚æœä¸Šé¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¯»å–
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url)

        # åŸºç¡€æ¸…æ´—
        df.columns = df.columns.str.strip()
        for col in ['Sale Price', 'Sale PSF', 'Area (sqft)']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'Sale Date' in df.columns:
            df['Sale Date'] = pd.to_datetime(df['Sale Date'], errors='coerce')
            df['Sale Year'] = df['Sale Date'].dt.year

        if 'BLK' in df.columns: df['BLK'] = df['BLK'].astype(str).str.strip()
        if 'Stack' in df.columns: df['Stack'] = df['Stack'].astype(str).str.strip()

        return df
    except Exception as e:
        st.error(f"æ•°æ®è¯»å–é”™è¯¯: {e}")
        return None

def auto_categorize(df, method):
    if method == "æŒ‰æ¥¼åº§ (Block)": return df['BLK']
    elif method == "æŒ‰å§å®¤ç±»å‹ (å¦‚æœæ•°æ®æœ‰)":
        cols = [c for c in df.columns if 'Bedroom' in c or 'Type' in c]
        return df[cols[0]].astype(str) if cols else pd.Series(["æœªçŸ¥"] * len(df))
    else: 
        def size_bin(area):
            if area < 800: return "Small (<800sf)"
            if area < 1200: return "Medium (800-1.2k)"
            if area < 1600: return "Large (1.2k-1.6k)"
            if area < 2500: return "X-Large (1.6k-2.5k)"
            return "Giant (>2.5k)"
        return df['Area (sqft)'].apply(size_bin)

def estimate_inventory(df, category_col='Category'):
    """
    V2 å‡çº§ç‰ˆåº“å­˜æ¨å®šç®—æ³•ï¼šåŸºäºåŒæ¥¼æ ‹æœ€å¤§å†å²æˆäº¤å¯†åº¦
    è§£å†³ Maisonette è·³å±‚ç¼–å·å¯¼è‡´çš„åº“å­˜é«˜ä¼°é—®é¢˜
    """
    # 1. åŸºç¡€æ£€æŸ¥
    if 'BLK' not in df.columns:
        return {}
    
    # ç¡®ä¿ Stack å­˜åœ¨ï¼Œå¦‚æœæ²¡æœ‰ Stack åˆ—ï¼Œå°è¯•ä» Unit_ID æˆ–å…¶ä»–æ–¹å¼æ— æ³•æ¨å®šï¼Œåªèƒ½é€€å›æ‰‹åŠ¨
    if 'Stack' not in df.columns:
        return {}

    # 2. è®¡ç®—æ¯ä¸ª Stack çš„"å†å²å¯è§å®¹é‡" (Observed Capacity)
    # é€»è¾‘ï¼šç»Ÿè®¡æ¯ä¸ª Block-Stack ç»„åˆä¸‹ï¼Œæœ‰å¤šå°‘ä¸ªå”¯ä¸€çš„å•ä½è¢«äº¤æ˜“è¿‡
    # æ³¨æ„ï¼šè¿™é‡Œç”¨ Unit_ID (BLK-Stack-Floor) å»é‡ï¼Œæˆ–è€…ç›´æ¥æ ¹æ® Floor å»é‡
    if 'Floor' in df.columns:
        # ç»Ÿè®¡æ¯ä¸ª stack å–è¿‡å¤šå°‘ä¸ªä¸åŒçš„æ¥¼å±‚
        stack_counts = df.groupby([category_col, 'BLK', 'Stack'])['Floor'].nunique().reset_index(name='Observed_Count')
    else:
        # å¦‚æœæ²¡æœ‰ Floor åˆ—ï¼ŒæŒ‰è¡Œæ•°ä¼°ç®—ï¼ˆä¸å¤ªå‡†ï¼Œä½†æ¯”æ²¡æœ‰å¥½ï¼‰
        stack_counts = df.groupby([category_col, 'BLK', 'Stack']).size().reset_index(name='Observed_Count')

    # 3. å¯»æ‰¾æ¯æ ‹æ¥¼çš„"æ ‡å‡†å®¹é‡" (Block Capacity)
    # å‡è®¾ï¼šåŒä¸€æ ‹æ¥¼é‡Œï¼Œæ‰€æœ‰ Stack çš„é«˜åº¦åº”è¯¥æ˜¯ä¸€æ ·çš„ã€‚
    # æˆ‘ä»¬å–è¯¥æ ‹æ¥¼é‡Œæ‰€æœ‰ Stack ä¸­ï¼ŒObserved_Count æœ€å¤§çš„é‚£ä¸ªå€¼ï¼Œä½œä¸ºè¯¥æ¥¼çš„æ ‡å‡†å±‚æ•°ã€‚
    # (è¿™èƒ½æœ‰æ•ˆè§£å†³æŸäº› Stack äº¤æ˜“å°‘å¯¼è‡´è¢«ä½ä¼°çš„é—®é¢˜)
    block_max_density = stack_counts.groupby([category_col, 'BLK'])['Observed_Count'].max().reset_index(name='Max_Stack_Capacity')

    # 4. ç»Ÿè®¡æ¯æ ‹æ¥¼æœ‰å¤šå°‘ä¸ª Stack
    # é€»è¾‘ï¼šçœ‹å†å²ä¸Šè¯¥ Block å‡ºç°è¿‡å¤šå°‘ä¸ªä¸åŒçš„ Stack ç¼–å·
    block_stack_counts = stack_counts.groupby([category_col, 'BLK'])['Stack'].nunique().reset_index(name='Num_Stacks')

    # 5. åˆå¹¶è®¡ç®—
    block_estimates = pd.merge(block_max_density, block_stack_counts, on=[category_col, 'BLK'])
    
    # å•æ ‹æ¥¼åº“å­˜ = Stackæ•°é‡ * æ ‡å‡†Stackå®¹é‡
    block_estimates['Est_Block_Inv'] = block_estimates['Num_Stacks'] * block_estimates['Max_Stack_Capacity']
    
    # 6. æŒ‰æˆ·å‹åˆ†ç±»æ±‡æ€»
    final_estimates = block_estimates.groupby(category_col)['Est_Block_Inv'].sum().to_dict()
    
    return final_estimates

# --- 4. ä¸»ç¨‹åºé€»è¾‘ ---

df = None

# åŠ è½½é€»è¾‘
if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
    if uploaded_file:
        df = load_data(uploaded_file)
elif sheet_url:
    df = load_data(sheet_url)

if df is not None:
    # 4.1 åˆ†ç±»ä¸åº“å­˜
    df['Category'] = auto_categorize(df, category_method)
    unique_cats = sorted(df['Category'].unique())
    inventory_map = {}

    with inventory_container:
        if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (åŸºäºStackæœ€é«˜æ¥¼å±‚)" and 'Stack' in df.columns and 'Floor' in df.columns:
            st.success("AI åº“å­˜æ¨å®šå·²æ¿€æ´»")
            estimated_inv = estimate_inventory(df, 'Category')
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                est_val = int(estimated_inv.get(cat, 100))
                with cols[i % 2]:
                    # å…è®¸åœ¨æ¨å®šåŸºç¡€ä¸Šä¿®æ”¹
                    val = st.number_input(f"[{cat}] åº“å­˜", value=est_val, min_value=1, key=f"inv_{i}")
                    inventory_map[cat] = val
        else:
            st.info("è¯·è¾“å…¥å„æˆ·å‹æ€»æˆ·æ•°ï¼š")
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                with cols[i % 2]:
                    val = st.number_input(f"[{cat}] æ€»æˆ·æ•°", value=100, min_value=1, key=f"inv_{i}")
                    inventory_map[cat] = val

    total_project_inventory = sum(inventory_map.values())

    # --- 5. ä»ªè¡¨ç›˜å±•ç¤º ---
    st.title(f"ğŸ™ï¸ {project_name} å¸‚åœºé€è§†")
    st.caption(f"æ•°æ®èŒƒå›´: {df['Sale Date'].min().date()} è‡³ {df['Sale Date'].max().date()} | æ€»äº¤æ˜“: {len(df)} å®—")

    # 5.1 KPI (YTD)
    current_year = datetime.now().year 
    df_this_year = df[df['Sale Year'] == current_year]
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric(f"{current_year}å¹´ æˆäº¤é‡", f"{len(df_this_year)} å®—")
    if len(df_this_year) > 0:
        col2.metric(f"{current_year} å‡å°ºä»·", f"${df_this_year['Sale PSF'].mean():,.0f} psf")
        col3.metric(f"{current_year} æœ€é«˜ä»·", f"${df_this_year['Sale Price'].max()/1e6:.2f}M")
    else:
        col2.metric(f"{current_year} å‡å°ºä»·", "-")
        col3.metric(f"{current_year} æœ€é«˜ä»·", "-")
    
    turnover_ytd = (len(df_this_year) / total_project_inventory * 100) if total_project_inventory > 0 else 0
    col4.metric(f"{current_year} æ•´ä½“æ¢æ‰‹ç‡", f"{turnover_ytd:.2f}%")

    st.divider()

    # 5.2 è¶‹åŠ¿å›¾ (Trend Chart)
    st.subheader("ğŸ“ˆ ä»·æ ¼ä¸æˆäº¤é‡è¶‹åŠ¿")
    
    col_ctrl1, col_ctrl2 = st.columns([1, 3])
    with col_ctrl1:
        freq_map = {"å¹´ (Year)": "Y", "å­£åº¦ (Quarter)": "Q", "æœˆ (Month)": "M"}
        freq_sel = st.selectbox("æ—¶é—´ç²’åº¦", list(freq_map.keys()))
        freq_code = freq_map[freq_sel]
        
        # æ™ºèƒ½æ—¶é—´èŒƒå›´ (é”å®šé¦–å°¾)
        min_d = df['Sale Date'].min().date().replace(day=1)
        max_d_raw = df['Sale Date'].max().date()
        last_day = calendar.monthrange(max_d_raw.year, max_d_raw.month)[1]
        max_d = max_d_raw.replace(day=last_day)
        
        date_range = st.date_input("é€‰æ‹©æ—¶é—´èŒƒå›´", [min_d, max_d])

    if len(date_range) == 2:
        start_d = pd.to_datetime(date_range[0])
        end_d = pd.to_datetime(date_range[1]) + timedelta(days=1) - timedelta(seconds=1)
        mask = (df['Sale Date'] >= start_d) & (df['Sale Date'] <= end_d)
        df_filtered = df.loc[mask]
    else:
        df_filtered = df

    trend_data = df_filtered.set_index('Sale Date').groupby('Category').resample(freq_code).agg({
        'Sale PSF': 'mean', 'Sale Price': 'count'
    }).rename(columns={'Sale Price': 'Volume'}).reset_index()

    # Plotly ç»˜å›¾
    fig = px.line(
        trend_data, x='Sale Date', y='Sale PSF', color='Category', 
        markers=True, symbol='Category',
        title=f"{project_name} å°ºä»·èµ°åŠ¿ ({freq_sel})",
        color_discrete_sequence=[chart_color, "#2E86C1", "#28B463", "#D35400", "#8E44AD"]
    )
    
    fig.update_traces(connectgaps=True) # è‡ªåŠ¨è¿æ¥æ–­ç‚¹
    fig.update_layout(
        font=dict(size=chart_font_size, family="Arial"),
        title=dict(font=dict(size=chart_font_size + 4)),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, title=None),
        hovermode="x unified"
    )
    
    # å¼ºåŠ›ä¸‹è½½é…ç½®
    st.plotly_chart(
        fig, use_container_width=True,
        config={
            'displayModeBar': True,
            'toImageButtonOptions': {
                'format': 'png', 'filename': f'{project_name}_chart',
                'height': exp_height, 'width': exp_width, 'scale': exp_scale
            },
            'displaylogo': False
        }
    )

    st.divider()

    # 5.3 æ¥¼æ ‹/å•å…ƒçƒ­åŠ›å›¾
    st.subheader("ğŸ¢ æ¥¼æ ‹ä¸å•å…ƒçƒ­åº¦")
    analysis_dim = st.radio("åˆ†æç»´åº¦", ["æŒ‰æ¥¼æ ‹ (Block)", "æŒ‰å…·ä½“å•å…ƒ (Stack)"], horizontal=True, label_visibility="collapsed")
    
    if analysis_dim == "æŒ‰æ¥¼æ ‹ (Block)":
        block_stats = df.groupby('BLK').agg({'Sale Price': 'count','Sale PSF': 'mean'}).reset_index().rename(columns={'Sale Price': 'Volume'})
        fig_blk = px.bar(block_stats, x='BLK', y='Volume', color='Sale PSF', title="å„æ¥¼æ ‹å†å²æˆäº¤é‡", color_continuous_scale="Blues")
        fig_blk.update_layout(font=dict(size=chart_font_size))
        st.plotly_chart(fig_blk, use_container_width=True, config={'toImageButtonOptions': {'height': exp_height, 'width': exp_width, 'scale': exp_scale}})
    else:
        if 'Stack' in df.columns:
            stack_stats = df.groupby(['BLK', 'Stack']).size().reset_index(name='Volume')
            stack_stats['Label'] = stack_stats['BLK'].astype(str) + "-" + stack_stats['Stack'].astype(str)
            fig_stack = px.treemap(stack_stats, path=['BLK', 'Stack'], values='Volume', title="å•å…ƒçƒ­åŠ›å›¾", color='Volume', color_continuous_scale="Reds")
            fig_stack.update_layout(font=dict(size=chart_font_size))
            st.plotly_chart(fig_stack, use_container_width=True, config={'toImageButtonOptions': {'height': exp_height, 'width': exp_width, 'scale': exp_scale}})
        else:
            st.warning("CSV æ–‡ä»¶ä¸­æ‰¾ä¸åˆ° 'Stack' åˆ—ã€‚")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®æˆ–ä¸Šä¼  CSV æ–‡ä»¶ã€‚")