# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import calendar

# ==========================================
# ğŸ”§ 1. é…ç½®ä¸­å¿ƒ (é¡¹ç›®åˆ—è¡¨)
# ==========================================
try:
    project_config = dict(st.secrets["projects"])
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}
    PROJECTS.update(project_config)
except:
    PROJECTS = {
        "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None,
        # "ğŸ¢ Braddell View": "https://docs.google.com/spreadsheets/d/e/...", 
    }

# ==========================================
# ğŸ–¥ï¸ 2. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(page_title="HAOæ•°æ®ä¸­å° Pro", layout="wide", page_icon="ğŸ§­")

# ==========================================
# ğŸ› ï¸ 3. æ ¸å¿ƒç®—æ³•å‡½æ•°åº“
# ==========================================

@st.cache_data(ttl=300)
def load_data(file_or_url):
    """è¯»å–æ•°æ®å¹¶æ™ºèƒ½æ¸…æ´—"""
    try:
        if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
        try:
            df_temp = pd.read_csv(file_or_url, header=None, nrows=20)
            header_row = -1
            for i, row in df_temp.iterrows():
                row_str = row.astype(str).str.cat(sep=',')
                if "Sale Date" in row_str or "BLK" in row_str:
                    header_row = i
                    break
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url, header=header_row if header_row != -1 else 0)
        except:
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url)

        df.columns = df.columns.str.strip()
        for col in ['Sale Price', 'Sale PSF', 'Area (sqft)']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'Sale Date' in df.columns:
            df['Sale Date'] = pd.to_datetime(df['Sale Date'], errors='coerce')
            df['Sale Year'] = df['Sale Date'].dt.year

        if 'BLK' in df.columns: df['BLK'] = df['BLK'].astype(str).str.strip()
        if 'Stack' in df.columns: df['Stack'] = df['Stack'].astype(str).str.strip()
        if 'Floor' in df.columns: df['Floor_Num'] = pd.to_numeric(df['Floor'], errors='coerce')

        return df
    except Exception as e:
        st.error(f"æ•°æ®è¯»å–é”™è¯¯: {e}")
        return None

def auto_categorize(df, method):
    """æ™ºèƒ½æˆ·å‹åˆ†ç±»"""
    if method == "æŒ‰æ¥¼åº§ (Block)": 
        return df['BLK']
    elif method == "æŒ‰å§å®¤ç±»å‹ (å¦‚æœæ•°æ®æœ‰)":
        cols = [c for c in df.columns if 'Bedroom' in c or 'Type' in c]
        return df[cols[0]].astype(str) if cols else pd.Series(["æœªçŸ¥"] * len(df))
    else: 
        def size_bin(area):
            if area < 800: return "Small (<800sf)"
            if area < 1200: return "Medium (800-1.2k)"
            if area < 1600: return "Large (1.2k-1.6k)"
            if area < 2500: return "X-Large (1.6k-2.5k)"
            return "Giant (>2.5k)"
        return df['Area (sqft)'].apply(size_bin)

def mark_penthouse(df):
    """å…¨å±€æ ‡è®° Penthouse (è§£å†³ KeyError æ ¸å¿ƒ)"""
    if 'Area (sqft)' not in df.columns or 'Category' not in df.columns:
        return pd.Series([False] * len(df))
    
    # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„ä¸­ä½æ•°é¢ç§¯
    medians = df.groupby('Category')['Area (sqft)'].median()
    
    def check(row):
        med = medians.get(row['Category'], 0)
        # è¶…è¿‡ä¸­ä½æ•° 1.4 å€è§†ä¸ºç‰¹æ®Šæˆ·å‹
        return row['Area (sqft)'] > (med * 1.4)
    
    return df.apply(check, axis=1)

def estimate_inventory(df, category_col='Category'):
    """V7 æ™ºèƒ½åº“å­˜ç®—æ³• (Category Fallback Mode)"""
    if 'BLK' not in df.columns or 'Floor_Num' not in df.columns:
        return {}

    df = df.dropna(subset=['Floor_Num']).copy()
    
    # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„"åŸºå‡†æœ€é«˜å±‚æ•°"
    cat_benchmark_floors = {}
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        std_df = cat_df[~cat_df['Is_Special']] # è¿™é‡Œç›´æ¥ä½¿ç”¨å…¨å±€è®¡ç®—å¥½çš„ Is_Special
        max_floor = std_df['Floor_Num'].max() if not std_df.empty else 1
        cat_benchmark_floors[cat] = max_floor

    block_inventory_map = {} 
    category_total_map = {}

    # é€æ ‹è®¡ç®—
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        cat_total_inv = 0
        benchmark_floor = cat_benchmark_floors.get(cat, 1)
        
        for blk in cat_df['BLK'].unique():
            blk_df = cat_df[cat_df['BLK'] == blk]
            
            num_stacks = blk_df['Stack'].nunique() if 'Stack' in blk_df.columns else 1
            std_units = blk_df[~blk_df['Is_Special']]
            local_max = std_units['Floor_Num'].max() if not std_units.empty else 0
            
            final_floors_count = len(std_units['Floor_Num'].unique()) 
            
            # æ™ºèƒ½è¡¥å…¨é€»è¾‘
            if local_max < (benchmark_floor - 2):
                best_blk_floors = 0
                for b_temp in cat_df['BLK'].unique():
                    f_set = set(cat_df[(cat_df['BLK']==b_temp) & (~cat_df['Is_Special'])]['Floor_Num'].unique())
                    if len(f_set) > best_blk_floors:
                        best_blk_floors = len(f_set)
                final_floors_count = best_blk_floors
            
            base_inv = num_stacks * final_floors_count
            
            ph_inv = 0
            if 'Stack' in blk_df.columns:
                ph_inv = blk_df[blk_df['Is_Special']].groupby(['Stack', 'Floor_Num']).ngroups
            else:
                ph_inv = len(blk_df[blk_df['Is_Special']])
            
            total_blk_inv = int(base_inv + ph_inv)
            block_inventory_map[blk] = total_blk_inv
            cat_total_inv += total_blk_inv

        category_total_map[cat] = int(cat_total_inv)
            
    st.session_state['block_inv_debug'] = block_inventory_map
    return category_total_map

# ==========================================
# ğŸ¨ 4. ä¾§è¾¹æ ä¸ä¸»ç•Œé¢é€»è¾‘
# ==========================================

with st.sidebar:
    st.header("1. é¡¹ç›®åˆ‡æ¢")
    selected_project = st.selectbox("é€‰æ‹©è¦åˆ†æçš„é¡¹ç›®", list(PROJECTS.keys()))
    
    sheet_url = PROJECTS[selected_project]
    uploaded_file = None
    project_name = selected_project

    if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
        uploaded_file = st.file_uploader("æ‹–å…¥ CSV æ–‡ä»¶", type=['csv'])
        if uploaded_file:
            project_name = uploaded_file.name.replace(".csv", "")
    else:
        st.success(f"â˜ï¸ å·²è¿æ¥äº‘ç«¯: {selected_project}")

    st.markdown("---")
    st.header("2. ç»Ÿè®¡è®¾å®š")

    category_method = st.selectbox("åˆ†ç±»ä¾æ®", ["æŒ‰æˆ·å‹é¢ç§¯æ®µ (è‡ªåŠ¨åˆ†ç®±)", "æŒ‰æ¥¼åº§ (Block)", "æŒ‰å§å®¤ç±»å‹"])
    inventory_mode = st.radio("åº“å­˜è®¡ç®—æ¨¡å¼", ["ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)", "ğŸ– æ‰‹åŠ¨è¾“å…¥"], index=0)
    inventory_container = st.container()

    st.markdown("---")
    st.header("3. å¯¼å‡ºè®¾ç½®")
    chart_font_size = st.number_input("å›¾è¡¨å­—å·", value=16, min_value=10)
    chart_color = st.color_picker("ä¸»è‰²è°ƒ", "#F63366")
    
    st.caption("ğŸ“· å›¾ç‰‡ä¸‹è½½å°ºå¯¸")
    exp_width = st.number_input("å®½åº¦ (px)", value=1200, step=100)
    exp_height = st.number_input("é«˜åº¦ (px)", value=675, step=100)
    exp_scale = st.slider("æ¸…æ™°åº¦", 1, 5, 2)

# --- æ•°æ®åŠ è½½ ---
df = None
if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
    if uploaded_file: df = load_data(uploaded_file)
elif sheet_url:
    df = load_data(sheet_url)

if df is not None:
    # 4.1 é¢„å¤„ç†æµç¨‹ (å…³é”®ä¿®å¤æ­¥éª¤)
    df['Category'] = auto_categorize(df, category_method)
    # --- ä¿®å¤ç‚¹ï¼šåœ¨è¿™é‡Œå…¨å±€è®¡ç®— Is_Specialï¼Œåç»­æ‰€æœ‰åŠŸèƒ½éƒ½å¯ä»¥ç›´æ¥ç”¨ ---
    df['Is_Special'] = mark_penthouse(df)
    
    unique_cats = sorted(df['Category'].unique())
    inventory_map = {}

    with inventory_container:
        if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'Stack' in df.columns and 'Floor_Num' in df.columns:
            st.info("å·²å¯ç”¨ V7 æ™ºèƒ½åº“å­˜ç®—æ³• (è‡ªåŠ¨è¡¥å…¨å†·é—¨æ¥¼æ ‹)")
            estimated_inv = estimate_inventory(df, 'Category')
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                est_val = int(estimated_inv.get(cat, 100))
                with cols[i % 2]:
                    # å…³é”®ä¿®æ”¹ï¼škey ä¸­åŠ å…¥ category_methodï¼Œç¡®ä¿åˆ‡æ¢åˆ†ç±»æ—¶å¼ºåˆ¶åˆ·æ–°
                    val = st.number_input(
                        f"[{cat}] åº“å­˜", 
                        value=est_val, 
                        min_value=1, 
                        key=f"inv_{category_method}_{i}"  # <--- æ”¹äº†è¿™é‡Œ
                    )
                    inventory_map[cat] = val
        else:
            # ... (æ‰‹åŠ¨æ¨¡å¼åŒç†) ...
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                with cols[i % 2]:
                    val = st.number_input(
                        f"[{cat}]", 
                        value=100, 
                        min_value=1, 
                        key=f"inv_manual_{category_method}_{i}" # <--- æ”¹äº†è¿™é‡Œ
                    )
                    inventory_map[cat] = val

    total_project_inventory = sum(inventory_map.values())
    
    # ğŸ•µï¸â€â™€ï¸ åº“å­˜å®¡è®¡
    if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'block_inv_debug' in st.session_state:
        with st.expander(f"ğŸ•µï¸â€â™€ï¸ æŸ¥çœ‹æ¯æ ‹æ¥¼çš„å…·ä½“æ¨å®šæ•°æ® (Debug) - æ€»è®¡: {total_project_inventory}æˆ·"):
            debug_map = st.session_state['block_inv_debug']
            debug_df = pd.DataFrame(list(debug_map.items()), columns=['Block', 'Est. Inventory'])
            if 'BLK' in df.columns:
                actual_vol = df['BLK'].value_counts().reset_index()
                actual_vol.columns = ['Block', 'Sold Volume']
                audit_df = pd.merge(debug_df, actual_vol, on='Block', how='left').fillna(0)
                audit_df['Sold Volume'] = audit_df['Sold Volume'].astype(int)
                audit_df['Coverage %'] = (audit_df['Sold Volume'] / audit_df['Est. Inventory'] * 100)
                st.dataframe(audit_df.sort_values('Block'), use_container_width=True, 
                             column_config={"Coverage %": st.column_config.ProgressColumn("å·²å”®å æ¯”", format="%.1f%%", min_value=0, max_value=100)})

    # --- 5. ä»ªè¡¨ç›˜å±•ç¤º ---
    st.title(f"ğŸ™ï¸ {project_name} å¸‚åœºé€è§†")
    st.caption(f"æ•°æ®èŒƒå›´: {df['Sale Date'].min().date()} è‡³ {df['Sale Date'].max().date()} | æ€»äº¤æ˜“: {len(df)} å®—")

    # 5.1 KPI
    current_year = datetime.now().year 
    df_this_year = df[df['Sale Year'] == current_year]
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric(f"{current_year}å¹´ æˆäº¤é‡", f"{len(df_this_year)} å®—")
    if len(df_this_year) > 0:
        col2.metric(f"{current_year} å‡å°ºä»·", f"${df_this_year['Sale PSF'].mean():,.0f} psf")
        col3.metric(f"{current_year} æœ€é«˜ä»·", f"${df_this_year['Sale Price'].max()/1e6:.2f}M")
    else:
        col2.metric(f"{current_year} å‡å°ºä»·", "-")
        col3.metric(f"{current_year} æœ€é«˜ä»·", "-")
    
    turnover_ytd = (len(df_this_year) / total_project_inventory * 100) if total_project_inventory > 0 else 0
    col4.metric(f"{current_year} æ•´ä½“æ¢æ‰‹ç‡", f"{turnover_ytd:.2f}%")

    st.divider()

    # 5.2 è¶‹åŠ¿å›¾
    st.subheader("ğŸ“ˆ ä»·æ ¼ä¸æˆäº¤é‡è¶‹åŠ¿")
    col_ctrl1, col_ctrl2 = st.columns([1, 3])
    with col_ctrl1:
        freq_map = {"å¹´ (Year)": "Y", "å­£åº¦ (Quarter)": "Q", "æœˆ (Month)": "M"}
        freq_sel = st.selectbox("æ—¶é—´ç²’åº¦", list(freq_map.keys()))
        freq_code = freq_map[freq_sel]
        
        min_d = df['Sale Date'].min().date().replace(day=1)
        max_d_raw = df['Sale Date'].max().date()
        last_day = calendar.monthrange(max_d_raw.year, max_d_raw.month)[1]
        max_d = max_d_raw.replace(day=last_day)
        date_range = st.date_input("é€‰æ‹©æ—¶é—´èŒƒå›´", [min_d, max_d])

    if len(date_range) == 2:
        start_d = pd.to_datetime(date_range[0])
        end_d = pd.to_datetime(date_range[1]) + timedelta(days=1) - timedelta(seconds=1)
        mask = (df['Sale Date'] >= start_d) & (df['Sale Date'] <= end_d)
        df_filtered = df.loc[mask]
    else:
        df_filtered = df

    trend_data = df_filtered.set_index('Sale Date').groupby('Category').resample(freq_code).agg({
        'Sale PSF': 'mean', 'Sale Price': 'count'
    }).rename(columns={'Sale Price': 'Volume'}).reset_index()

    fig = px.line(
        trend_data, x='Sale Date', y='Sale PSF', color='Category', 
        markers=True, symbol='Category',
        title=f"{project_name} å°ºä»·èµ°åŠ¿ ({freq_sel})",
        color_discrete_sequence=[chart_color, "#2E86C1", "#28B463", "#D35400", "#8E44AD"]
    )
    fig.update_traces(connectgaps=True)
    fig.update_layout(
        font=dict(size=chart_font_size, family="Arial"),
        title=dict(font=dict(size=chart_font_size + 4)),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, title=None),
        hovermode="x unified"
    )
    st.plotly_chart(fig, use_container_width=True, config={
        'displayModeBar': True,
        'toImageButtonOptions': {'format': 'png', 'filename': f'{project_name}_trend', 'height': exp_height, 'width': exp_width, 'scale': exp_scale},
        'displaylogo': False
    })

    st.divider()

    # 5.3 æ¥¼å®‡é€è§† (Tower View)
    st.subheader("ğŸ¢ æ¥¼å®‡é€è§† (Tower View)")
    st.caption("Xè½´=Stack(å•å…ƒ), Yè½´=Floor(æ¥¼å±‚)ã€‚ç°è‰²=ç†è®ºå­˜åœ¨ä½†æœªäº¤æ˜“(åº“å­˜), å½©è‰²=å†å²äº¤æ˜“")
    
    if 'BLK' in df.columns:
        blk_counts = df['BLK'].value_counts()
        selected_blk = st.selectbox("é€‰æ‹©æ¥¼æ ‹", blk_counts.index.tolist())
        
        if selected_blk:
            blk_df = df[df['BLK'] == selected_blk].copy()
            
            # --- å¯è§†åŒ–æ•°æ®å‡†å¤‡ ---
            cat_this = blk_df['Category'].iloc[0]
            cat_df_all = df[df['Category'] == cat_this]
            
            # 1. å¯»æ‰¾åŸºå‡†å±‚æ•°
            std_units_cat = cat_df_all[~cat_df_all['Is_Special']]
            max_cat_floor = std_units_cat['Floor_Num'].max() if not std_units_cat.empty else 1
            
            # 2. æœ¬åœ°æ ‡å‡†å±‚
            std_units_local = blk_df[~blk_df['Is_Special']]
            local_floors = set(std_units_local['Floor_Num'].unique())
            
            # 3. æ™ºèƒ½è¡¥å…¨
            final_floors_set = local_floors.copy()
            if (len(local_floors) > 0) and (max(local_floors) < max_cat_floor - 2):
                all_cat_floors = set(std_units_cat['Floor_Num'].unique())
                final_floors_set = all_cat_floors
            
            all_stacks = sorted(blk_df['Stack'].unique()) if 'Stack' in blk_df.columns else ['Unknown']
            
            grid_data = []
            for stack in all_stacks:
                ph_floors = blk_df[(blk_df['Stack'] == stack) & (blk_df['Is_Special'])]['Floor_Num'].unique()
                theoretical_floors = final_floors_set.union(set(ph_floors))
                
                for floor in theoretical_floors:
                    match = blk_df[(blk_df['Stack'] == stack) & (blk_df['Floor_Num'] == floor)]
                    if not match.empty:
                        latest = match.sort_values('Sale Date', ascending=False).iloc[0]
                        grid_data.append({
                            'Stack': stack, 'Floor': floor, 'Status': 'Sold',
                            'PSF': int(latest['Sale PSF']), 'Date': latest['Sale Date'].strftime('%Y-%m')
                        })
                    else:
                        grid_data.append({
                            'Stack': stack, 'Floor': floor, 'Status': 'Stock',
                            'PSF': 0, 'Date': '-'
                        })
            
            viz_df = pd.DataFrame(grid_data)
            
            if not viz_df.empty:
                fig_tower = go.Figure()
                
                # åº“å­˜å±‚
                df_stock = viz_df[viz_df['Status'] == 'Stock']
                fig_tower.add_trace(go.Scatter(
                    x=df_stock['Stack'], y=df_stock['Floor'], mode='markers',
                    marker=dict(symbol='square', size=18, color='lightgrey', line=dict(width=1, color='grey')),
                    name='åº“å­˜ (æœªå”®)', hoverinfo='text',
                    text=[f"Stack {s} #{f}<br>åº“å­˜" for s, f in zip(df_stock['Stack'], df_stock['Floor'])]
                ))
                
                # äº¤æ˜“å±‚
                df_sold = viz_df[viz_df['Status'] == 'Sold']
                fig_tower.add_trace(go.Scatter(
                    x=df_sold['Stack'], y=df_sold['Floor'], mode='markers',
                    marker=dict(
                        symbol='square', size=18, color=df_sold['PSF'], colorscale='RdBu_r',
                        colorbar=dict(title="æœ€æ–° PSF"), line=dict(width=1, color='black')
                    ),
                    name='å·²å”®', hoverinfo='text',
                    text=[f"Stack {s} #{f}<br>${p} psf<br>{d}" for s, f, p, d in zip(df_sold['Stack'], df_sold['Floor'], df_sold['PSF'], df_sold['Date'])]
                ))
                
                fig_tower.update_layout(
                    title=f"Block {selected_blk} åº“å­˜é€è§† (è¡¥å…¨å)",
                    xaxis=dict(title="Stack", type='category'),
                    yaxis=dict(title="Floor", dtick=1),
                    height=600, width=800, plot_bgcolor='white'
                )
                st.plotly_chart(fig_tower, use_container_width=True, config={
                    'toImageButtonOptions': {'format': 'png', 'height': exp_height, 'width': exp_width, 'scale': exp_scale}
                })
                
                sold_count = len(df_sold)
                total_count = len(viz_df)
                st.info(f"ğŸ“Š é¢æ¿æ•°æ®ï¼šæ€»æ¨ç®— {total_count} æˆ· | å†å²æˆäº¤ {sold_count} æˆ· | è¦†ç›–ç‡ {(sold_count/total_count*100):.1f}%")
            else:
                st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆé€è§†å›¾")
    else:
        st.warning("CSV ç¼ºå°‘ BLK åˆ—ï¼Œæ— æ³•æ˜¾ç¤ºæ¥¼å®‡é€è§†")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©é¡¹ç›®æˆ–ä¸Šä¼  CSV æ–‡ä»¶ã€‚")