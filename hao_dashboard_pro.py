# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import calendar

# ==========================================
# ğŸ”§ 1. é…ç½®ä¸­å¿ƒ (é¡¹ç›®åˆ—è¡¨)
# ==========================================
try:
    project_config = dict(st.secrets["projects"])
    PROJECTS = {"ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None}
    PROJECTS.update(project_config)
except:
    PROJECTS = {
        "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV": None,
        # "ğŸ¢ Braddell View": "https://docs.google.com/spreadsheets/d/e/...", 
    }

# ==========================================
# ğŸ–¥ï¸ 2. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(page_title="HAOæ•°æ®ä¸­å° Pro", layout="wide", page_icon="ğŸ§­")

# ==========================================
# ğŸ› ï¸ 3. æ ¸å¿ƒç®—æ³•å‡½æ•°åº“
# ==========================================

@st.cache_data(ttl=300)
def load_data(file_or_url):
    """è¯»å–æ•°æ®å¹¶æ™ºèƒ½æ¸…æ´—"""
    try:
        if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
        try:
            df_temp = pd.read_csv(file_or_url, header=None, nrows=20)
            header_row = -1
            for i, row in df_temp.iterrows():
                row_str = row.astype(str).str.cat(sep=',')
                if "Sale Date" in row_str or "BLK" in row_str:
                    header_row = i
                    break
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url, header=header_row if header_row != -1 else 0)
        except:
            if hasattr(file_or_url, 'seek'): file_or_url.seek(0)
            df = pd.read_csv(file_or_url)

        df.columns = df.columns.str.strip()
        for col in ['Sale Price', 'Sale PSF', 'Area (sqft)']:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace(r'[$,]', '', regex=True)
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if 'Sale Date' in df.columns:
            df['Sale Date'] = pd.to_datetime(df['Sale Date'], errors='coerce')
            df['Sale Year'] = df['Sale Date'].dt.year

        if 'BLK' in df.columns: df['BLK'] = df['BLK'].astype(str).str.strip()
        if 'Stack' in df.columns: df['Stack'] = df['Stack'].astype(str).str.strip()
        if 'Floor' in df.columns: df['Floor_Num'] = pd.to_numeric(df['Floor'], errors='coerce')

        return df
    except Exception as e:
        st.error(f"æ•°æ®è¯»å–é”™è¯¯: {e}")
        return None

def auto_categorize(df, method):
    """æ™ºèƒ½æˆ·å‹åˆ†ç±» (V8: å®Œç¾æ”¯æŒ Bedroom Type)"""
    
    # 1. ä¼˜å…ˆå¤„ç†å§å®¤ç±»å‹ (å½“ç”¨æˆ·é€‰æ‹©æˆ–è‡ªåŠ¨æ£€æµ‹åˆ°æ—¶)
    if method == "æŒ‰å§å®¤æ•°é‡ (Bedroom Type)":
        # èƒ½å¤Ÿè¯†åˆ«çš„å¸¸è§åˆ—ååˆ—è¡¨
        target_cols = ['Bedroom Type', 'Bedroom_Type', 'Bedrooms', 'No. of Bedrooms', 'Type']
        found_col = None
        
        # ç²¾ç¡®æŸ¥æ‰¾
        for col in df.columns:
            if col.strip() in target_cols:
                found_col = col
                break
        
        # æ¨¡ç³ŠæŸ¥æ‰¾ (å¦‚æœä¸Šé¢æ²¡æ‰¾åˆ°)
        if not found_col:
            for col in df.columns:
                if 'Bedroom' in col:
                    found_col = col
                    break
        
        if found_col:
            # æ¸…æ´—æ•°æ®ï¼šè½¬æˆå­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºæ ¼ï¼Œç»Ÿä¸€å¤§å†™
            # æ•ˆæœ: "3br " -> "3BR", "3 br" -> "3BR"
            clean_series = df[found_col].astype(str).str.strip().str.upper()
            # å¯é€‰ï¼šå¦‚æœæ‚¨æƒ³æŠŠ '3BR' æ˜¾ç¤ºä¸º '3 Bedroom'ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ  .replace
            return clean_series
        else:
            return pd.Series(["æœªæ‰¾åˆ°å§å®¤åˆ—"] * len(df))

    # 2. æŒ‰æ¥¼åº§
    elif method == "æŒ‰æ¥¼åº§ (Block)": 
        return df['BLK']

    # 3. é»˜è®¤ï¼šæŒ‰é¢ç§¯åˆ†ç®± (ä»…ä½œä¸ºå¤‡é€‰)
    else: 
        def size_bin(area):
            if area < 800: return "Small (<800sf)"
            if area < 1200: return "Medium (800-1.2k)"
            if area < 1600: return "Large (1.2k-1.6k)"
            if area < 2500: return "X-Large (1.6k-2.5k)"
            return "Giant (>2.5k)"
        return df['Area (sqft)'].apply(size_bin)

def mark_penthouse(df):
    """å…¨å±€æ ‡è®° Penthouse (è§£å†³ KeyError æ ¸å¿ƒ)"""
    if 'Area (sqft)' not in df.columns or 'Category' not in df.columns:
        return pd.Series([False] * len(df))
    
    # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„ä¸­ä½æ•°é¢ç§¯
    medians = df.groupby('Category')['Area (sqft)'].median()
    
    def check(row):
        med = medians.get(row['Category'], 0)
        # è¶…è¿‡ä¸­ä½æ•° 1.4 å€è§†ä¸ºç‰¹æ®Šæˆ·å‹
        return row['Area (sqft)'] > (med * 1.4)
    
    return df.apply(check, axis=1)

def estimate_inventory(df, category_col='Category'):
    """V7 æ™ºèƒ½åº“å­˜ç®—æ³• (Category Fallback Mode)"""
    if 'BLK' not in df.columns or 'Floor_Num' not in df.columns:
        return {}

    df = df.dropna(subset=['Floor_Num']).copy()
    
    # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„"åŸºå‡†æœ€é«˜å±‚æ•°"
    cat_benchmark_floors = {}
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        std_df = cat_df[~cat_df['Is_Special']] # è¿™é‡Œç›´æ¥ä½¿ç”¨å…¨å±€è®¡ç®—å¥½çš„ Is_Special
        max_floor = std_df['Floor_Num'].max() if not std_df.empty else 1
        cat_benchmark_floors[cat] = max_floor

    block_inventory_map = {} 
    category_total_map = {}

    # é€æ ‹è®¡ç®—
    for cat in df[category_col].unique():
        cat_df = df[df[category_col] == cat]
        cat_total_inv = 0
        benchmark_floor = cat_benchmark_floors.get(cat, 1)
        
        for blk in cat_df['BLK'].unique():
            blk_df = cat_df[cat_df['BLK'] == blk]
            
            num_stacks = blk_df['Stack'].nunique() if 'Stack' in blk_df.columns else 1
            std_units = blk_df[~blk_df['Is_Special']]
            local_max = std_units['Floor_Num'].max() if not std_units.empty else 0
            
            final_floors_count = len(std_units['Floor_Num'].unique()) 
            
            # æ™ºèƒ½è¡¥å…¨é€»è¾‘
            if local_max < (benchmark_floor - 2):
                best_blk_floors = 0
                for b_temp in cat_df['BLK'].unique():
                    f_set = set(cat_df[(cat_df['BLK']==b_temp) & (~cat_df['Is_Special'])]['Floor_Num'].unique())
                    if len(f_set) > best_blk_floors:
                        best_blk_floors = len(f_set)
                final_floors_count = best_blk_floors
            
            base_inv = num_stacks * final_floors_count
            
            ph_inv = 0
            if 'Stack' in blk_df.columns:
                ph_inv = blk_df[blk_df['Is_Special']].groupby(['Stack', 'Floor_Num']).ngroups
            else:
                ph_inv = len(blk_df[blk_df['Is_Special']])
            
            total_blk_inv = int(base_inv + ph_inv)
            block_inventory_map[blk] = total_blk_inv
            cat_total_inv += total_blk_inv

        category_total_map[cat] = int(cat_total_inv)
            
    st.session_state['block_inv_debug'] = block_inventory_map
    return category_total_map

# ==========================================
# ğŸ¨ 4. ä¾§è¾¹æ ä¸ä¸»ç•Œé¢é€»è¾‘
# ==========================================

with st.sidebar:
    st.header("1. é¡¹ç›®åˆ‡æ¢")
    selected_project = st.selectbox("é€‰æ‹©è¦åˆ†æçš„é¡¹ç›®", list(PROJECTS.keys()))
    
    sheet_url = PROJECTS[selected_project]
    uploaded_file = None
    project_name = selected_project

    if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
        uploaded_file = st.file_uploader("æ‹–å…¥ CSV æ–‡ä»¶", type=['csv'])
        if uploaded_file:
            project_name = uploaded_file.name.replace(".csv", "")
    else:
        st.success(f"â˜ï¸ å·²è¿æ¥äº‘ç«¯: {selected_project}")

    st.markdown("---")
    st.header("2. ç»Ÿè®¡è®¾å®š")

# ... (åœ¨ st.header("2. ç»Ÿè®¡è®¾å®š") ä¸‹æ–¹) ...

    # === æ™ºèƒ½åˆ¤æ–­é»˜è®¤åˆ†ç±»æ–¹å¼ ===
    default_index = 0
    # æ£€æŸ¥æ•°æ®é‡Œæœ‰æ²¡æœ‰å§å®¤åˆ—
    has_bedroom_col = False
    if df is not None:
        possible_cols = ['Bedroom Type', 'Bedrooms', 'Type', 'Bedroom_Type']
        # åªè¦åˆ—åé‡ŒåŒ…å« Bedroom æˆ–è€…æ˜¯ä¸Šé¢çš„è¯ï¼Œå°±è®¤ä¸ºæ˜¯åŒ…å«å§å®¤æ•°æ®
        if any(c in df.columns for c in possible_cols) or any('Bedroom' in c for c in df.columns):
            has_bedroom_col = True
            default_index = 0 # å°† "æŒ‰å§å®¤æ•°é‡" è®¾ä¸ºé»˜è®¤

    # è°ƒæ•´é€‰é¡¹é¡ºåºï¼Œæ ¹æ®æ˜¯å¦æœ‰å§å®¤åˆ—åŠ¨æ€å˜åŒ–
    if has_bedroom_col:
        options = ["æŒ‰å§å®¤æ•°é‡ (Bedroom Type)", "æŒ‰æ¥¼åº§ (Block)", "æŒ‰æˆ·å‹é¢ç§¯æ®µ (è‡ªåŠ¨åˆ†ç®±)"]
    else:
        options = ["æŒ‰æˆ·å‹é¢ç§¯æ®µ (è‡ªåŠ¨åˆ†ç®±)", "æŒ‰æ¥¼åº§ (Block)", "æŒ‰å§å®¤æ•°é‡ (Bedroom Type)"]

    category_method = st.selectbox("åˆ†ç±»ä¾æ®", options, index=0)
    
    inventory_mode = st.radio("åº“å­˜è®¡ç®—æ¨¡å¼", ["ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)", "ğŸ– æ‰‹åŠ¨è¾“å…¥"], index=0)
    inventory_container = st.container()

    st.markdown("---")
    st.header("3. å¯¼å‡ºè®¾ç½®")
    chart_font_size = st.number_input("å›¾è¡¨å­—å·", value=16, min_value=10)
    chart_color = st.color_picker("ä¸»è‰²è°ƒ", "#F63366")
    
    st.caption("ğŸ“· å›¾ç‰‡ä¸‹è½½å°ºå¯¸")
    exp_width = st.number_input("å®½åº¦ (px)", value=1200, step=100)
    exp_height = st.number_input("é«˜åº¦ (px)", value=675, step=100)
    exp_scale = st.slider("æ¸…æ™°åº¦", 1, 5, 2)

# --- æ•°æ®åŠ è½½ ---
df = None
if selected_project == "ğŸ“‚ æ‰‹åŠ¨ä¸Šä¼  CSV":
    if uploaded_file: df = load_data(uploaded_file)
elif sheet_url:
    df = load_data(sheet_url)

if df is not None:
    # 4.1 é¢„å¤„ç†æµç¨‹ (å…³é”®ä¿®å¤æ­¥éª¤)
    df['Category'] = auto_categorize(df, category_method)
    # --- ä¿®å¤ç‚¹ï¼šåœ¨è¿™é‡Œå…¨å±€è®¡ç®— Is_Specialï¼Œåç»­æ‰€æœ‰åŠŸèƒ½éƒ½å¯ä»¥ç›´æ¥ç”¨ ---
    df['Is_Special'] = mark_penthouse(df)
    
    unique_cats = sorted(df['Category'].unique())
    inventory_map = {}

    with inventory_container:
        if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'Stack' in df.columns and 'Floor_Num' in df.columns:
            st.info("å·²å¯ç”¨ V7 æ™ºèƒ½åº“å­˜ç®—æ³• (è‡ªåŠ¨è¡¥å…¨å†·é—¨æ¥¼æ ‹)")
            estimated_inv = estimate_inventory(df, 'Category')
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                est_val = int(estimated_inv.get(cat, 100))
                with cols[i % 2]:
                    # å…³é”®ä¿®æ”¹ï¼škey ä¸­åŠ å…¥ category_methodï¼Œç¡®ä¿åˆ‡æ¢åˆ†ç±»æ—¶å¼ºåˆ¶åˆ·æ–°
                    val = st.number_input(
                        f"[{cat}] åº“å­˜", 
                        value=est_val, 
                        min_value=1, 
                        key=f"inv_{category_method}_{i}"  # <--- æ”¹äº†è¿™é‡Œ
                    )
                    inventory_map[cat] = val
        else:
            # ... (æ‰‹åŠ¨æ¨¡å¼åŒç†) ...
            cols = st.columns(2)
            for i, cat in enumerate(unique_cats):
                with cols[i % 2]:
                    val = st.number_input(
                        f"[{cat}]", 
                        value=100, 
                        min_value=1, 
                        key=f"inv_manual_{category_method}_{i}" # <--- æ”¹äº†è¿™é‡Œ
                    )
                    inventory_map[cat] = val

    total_project_inventory = sum(inventory_map.values())
    
    # ğŸ•µï¸â€â™€ï¸ åº“å­˜å®¡è®¡
    if inventory_mode == "ğŸ¤– è‡ªåŠ¨æ¨å®š (æ™ºèƒ½è¡¥å…¨)" and 'block_inv_debug' in st.session_state:
        with st.expander(f"ğŸ•µï¸â€â™€ï¸ æŸ¥çœ‹æ¯æ ‹æ¥¼çš„å…·ä½“æ¨å®šæ•°æ® (Debug) - æ€»è®¡: {total_project_inventory}æˆ·"):
            debug_map = st.session_state['block_inv_debug']
            debug_df = pd.DataFrame(list(debug_map.items()), columns=['Block', 'Est. Inventory'])
            if 'BLK' in df.columns:
                actual_vol = df['BLK'].value_counts().reset_index()
                actual_vol.columns = ['Block', 'Sold Volume']
                audit_df = pd.merge(debug_df, actual_vol, on='Block', how='left').fillna(0)
                audit_df['Sold Volume'] = audit_df['Sold Volume'].astype(int)
                audit_df['Coverage %'] = (audit_df['Sold Volume'] / audit_df['Est. Inventory'] * 100)
                st.dataframe(audit_df.sort_values('Block'), use_container_width=True, 
                             column_config={"Coverage %": st.column_config.ProgressColumn("å·²å”®å æ¯”", format="%.1f%%", min_value=0, max_value=100)})

    # --- 5. ä»ªè¡¨ç›˜å±•ç¤º ---
    st.title(f"ğŸ™ï¸ {project_name} å¸‚åœºé€è§†")
    st.caption(f"æ•°æ®èŒƒå›´: {df['Sale Date'].min().date()} è‡³ {df['Sale Date'].max().date()} | æ€»äº¤æ˜“: {len(df)} å®—")

    # 5.1 KPI
    current_year = datetime.now().year 
    df_this_year = df[df['Sale Year'] == current_year]
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric(f"{current_year}å¹´ æˆäº¤é‡", f"{len(df_this_year)} å®—")
    if len(df_this_year) > 0:
        col2.metric(f"{current_year} å‡å°ºä»·", f"${df_this_year['Sale PSF'].mean():,.0f} psf")
        col3.metric(f"{current_year} æœ€é«˜ä»·", f"${df_this_year['Sale Price'].max()/1e6:.2f}M")
    else:
        col2.metric(f"{current_year} å‡å°ºä»·", "-")
        col3.metric(f"{current_year} æœ€é«˜ä»·", "-")
    
    turnover_ytd = (len(df_this_year) / total_project_inventory * 100) if total_project_inventory > 0 else 0
    col4.metric(f"{current_year} æ•´ä½“æ¢æ‰‹ç‡", f"{turnover_ytd:.2f}%")

    st.divider()

    # 5.2 è¶‹åŠ¿å›¾
    st.subheader("ğŸ“ˆ ä»·æ ¼ä¸æˆäº¤é‡è¶‹åŠ¿")
    col_ctrl1, col_ctrl2 = st.columns([1, 3])
    with col_ctrl1:
        freq_map = {"å¹´ (Year)": "Y", "å­£åº¦ (Quarter)": "Q", "æœˆ (Month)": "M"}
        freq_sel = st.selectbox("æ—¶é—´ç²’åº¦", list(freq_map.keys()))
        freq_code = freq_map[freq_sel]
        
        min_d = df['Sale Date'].min().date().replace(day=1)
        max_d_raw = df['Sale Date'].max().date()
        last_day = calendar.monthrange(max_d_raw.year, max_d_raw.month)[1]
        max_d = max_d_raw.replace(day=last_day)
        date_range = st.date_input("é€‰æ‹©æ—¶é—´èŒƒå›´", [min_d, max_d])

    if len(date_range) == 2:
        start_d = pd.to_datetime(date_range[0])
        end_d = pd.to_datetime(date_range[1]) + timedelta(days=1) - timedelta(seconds=1)
        mask = (df['Sale Date'] >= start_d) & (df['Sale Date'] <= end_d)
        df_filtered = df.loc[mask]
    else:
        df_filtered = df

    trend_data = df_filtered.set_index('Sale Date').groupby('Category').resample(freq_code).agg({
        'Sale PSF': 'mean', 'Sale Price': 'count'
    }).rename(columns={'Sale Price': 'Volume'}).reset_index()

    fig = px.line(
        trend_data, x='Sale Date', y='Sale PSF', color='Category', 
        markers=True, symbol='Category',
        title=f"{project_name} å°ºä»·èµ°åŠ¿ ({freq_sel})",
        color_discrete_sequence=[chart_color, "#2E86C1", "#28B463", "#D35400", "#8E44AD"]
    )
    fig.update_traces(connectgaps=True)
    fig.update_layout(
        font=dict(size=chart_font_size, family="Arial"),
        title=dict(font=dict(size=chart_font_size + 4)),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, title=None),
        hovermode="x unified"
    )
    st.plotly_chart(fig, use_container_width=True, config={
        'displayModeBar': True,
        'toImageButtonOptions': {'format': 'png', 'filename': f'{project_name}_trend', 'height': exp_height, 'width': exp_width, 'scale': exp_scale},
        'displaylogo': False
    })

    st.divider()

# 5.3 æ¥¼å®‡é€è§† (Tower View) - V9 æ–°åŠ å¡ä¸“å±ç‰ˆ
    st.subheader("ğŸ¢ æ¥¼å®‡é€è§† (Tower View)")
    st.caption("è§†è§‰æŒ‡å—ï¼šğŸŸ¦ é¢œè‰²è¶Šæ·±=å°ºä»·è¶Šé«˜ | â¬œ æµ…ç°=åº“å­˜æ­»ç­¹")
    
    if 'BLK' in df.columns:
        blk_counts = df['BLK'].value_counts()
        selected_blk = st.selectbox("é€‰æ‹©æ¥¼æ ‹", blk_counts.index.tolist())
        
        if selected_blk:
            blk_df = df[df['BLK'] == selected_blk].copy()
            
            # --- 1. è®¡ç®—åº“å­˜éª¨æ¶ ---
            cat_this = blk_df['Category'].iloc[0]
            cat_df_all = df[df['Category'] == cat_this]
            
            # åŸºå‡†å±‚æ•° (åŒç±»æœ€é«˜)
            std_units_cat = cat_df_all[~cat_df_all['Is_Special']]
            max_cat_floor = std_units_cat['Floor_Num'].max() if not std_units_cat.empty else 1
            
            # æœ¬åœ°å±‚æ•°
            std_units_local = blk_df[~blk_df['Is_Special']]
            local_floors = set(std_units_local['Floor_Num'].unique())
            
            # æ™ºèƒ½è¡¥å…¨é€»è¾‘
            final_floors_set = local_floors.copy()
            
            # åªæœ‰å½“æœ¬åœ°å±‚æ•°æ˜æ˜¾ç¼ºå¤±æ—¶æ‰è¡¥å…¨
            if (len(local_floors) > 0) and (max(local_floors) < max_cat_floor - 2):
                 all_cat_floors = set(std_units_cat['Floor_Num'].unique())
                 final_floors_set = all_cat_floors

            # --- 2. æ„å»ºç²¾å‡†çš„ Y è½´ (å…³é”®ä¿®æ”¹) ---
            # æ”¶é›†æ‰€æœ‰éœ€è¦ç»˜åˆ¶çš„æ¥¼å±‚ï¼Œå¹¶æ’åº
            all_stacks = sorted(blk_df['Stack'].unique()) if 'Stack' in blk_df.columns else ['Unknown']
            
            # åˆå§‹æ¥¼å±‚é›†åˆ
            floors_to_plot = final_floors_set.copy()
            
            # åŠ ä¸Šç‰¹æ®Šçš„ Penthouse æ¥¼å±‚
            ph_floors = blk_df[blk_df['Is_Special']]['Floor_Num'].unique()
            for f in ph_floors:
                floors_to_plot.add(f)
            
            # æ’åºï¼šè½¬æˆæ•´æ•°æ’åºï¼Œå†è½¬æˆå­—ç¬¦ä¸²ä¾›åˆ†ç±»è½´ä½¿ç”¨
            sorted_floors_num = sorted(list(floors_to_plot))
            
            # è¿‡æ»¤æ‰ <= 0 çš„æ¥¼å±‚ (ä»¥é˜²ä¸‡ä¸€æ•°æ®æœ‰è¯¯)
            sorted_floors_num = [f for f in sorted_floors_num if f > 0]
            
            # æ„é€  Y è½´æ ‡ç­¾ (ä¿ç•™æ•°å­—æ ¼å¼ç”¨äºç”»å›¾ï¼Œä½†è½´è®¾ç½®ä¸º Category)
            
            # --- 3. å¡«å……æ•°æ®ç½‘æ ¼ ---
            grid_data = []
            
            for stack in all_stacks:
                # æ¯ä¸ª Stack çš„ç†è®ºæ¥¼å±‚
                this_stack_ph = blk_df[(blk_df['Stack'] == stack) & (blk_df['Is_Special'])]['Floor_Num'].unique()
                stack_theoretical = final_floors_set.union(set(this_stack_ph))
                
                for floor in sorted_floors_num:
                    # åªæœ‰å½“è¿™ä¸ªæ¥¼å±‚å±äºè¿™ä¸ª Stack çš„ç†è®ºèŒƒå›´æ—¶ï¼Œæ‰ç”»æ ¼å­
                    # (è¿™èƒ½è§£å†³å¤å¼æ¥¼çš„è·³å±‚æ˜¾ç¤ºé—®é¢˜)
                    if floor in stack_theoretical:
                        match = blk_df[(blk_df['Stack'] == stack) & (blk_df['Floor_Num'] == floor)]
                        
                        if not match.empty:
                            latest = match.sort_values('Sale Date', ascending=False).iloc[0]
                            grid_data.append({
                                'Stack': str(stack),
                                'Floor': str(int(floor)), # è½¬å­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶åˆ†ç±»
                                'Floor_Int': int(floor),  # ç•™ä¸ªæ•°å­—ç”¨äºæ’åº
                                'Type': 'Sold',
                                'PSF': int(latest['Sale PSF']),
                                'Price': f"${latest['Sale Price']/1e6:.2f}M",
                                'Year': latest['Sale Year']
                            })
                        else:
                            grid_data.append({
                                'Stack': str(stack),
                                'Floor': str(int(floor)),
                                'Floor_Int': int(floor),
                                'Type': 'Stock',
                                'PSF': None,
                                'Price': '-',
                                'Year': '-'
                            })

            viz_df = pd.DataFrame(grid_data)
            
            if not viz_df.empty:
                fig_tower = go.Figure()

                # ä¸ºäº†ä¿è¯ Y è½´é¡ºåºæ­£ç¡® (ä»ä½åˆ°é«˜)ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ Category Order
                y_category_order = [str(f) for f in sorted_floors_num]

                # å±‚1ï¼šåº“å­˜èƒŒæ™¯ (ç°è‰²)
                fig_tower.add_trace(go.Heatmap(
                    x=viz_df['Stack'],
                    y=viz_df['Floor'],
                    z=[1] * len(viz_df),
                    colorscale=[[0, '#eeeeee'], [1, '#eeeeee']],
                    showscale=False,
                    xgap=2, ygap=2, # åŠ å¤§é—´è·ï¼Œæ–¹æ ¼æ„Ÿæ›´å¼º
                    hoverinfo='skip'
                ))

                # å±‚2ï¼šæˆäº¤æ•°æ®
                sold_df = viz_df[viz_df['Type'] == 'Sold']
                if not sold_df.empty:
                    fig_tower.add_trace(go.Heatmap(
                        x=sold_df['Stack'],
                        y=sold_df['Floor'],
                        z=sold_df['PSF'],
                        colorscale='Teal',
                        colorbar=dict(title="æˆäº¤å°ºä»· ($psf)", len=0.5, y=0.5),
                        xgap=2, ygap=2,
                        hovertemplate=
                        "<b>Stack %{x} - #%{y}</b><br>" +
                        "ğŸ’° PSF: $%{z}<br>" +
                        "ğŸ·ï¸ æ€»ä»·: %{customdata[0]}<br>" +
                        "ğŸ“… å¹´ä»½: %{customdata[1]}<extra></extra>",
                        customdata=sold_df[['Price', 'Year']]
                    ))

                # --- 4. å¸ƒå±€ä¼˜åŒ– (å…³é”®ä¿®æ”¹) ---
                fig_tower.update_layout(
                    title=dict(text=f"Block {selected_blk} - æ¥¼å®‡åº“å­˜é€è§†", x=0.5),
                    
                    xaxis=dict(
                        title="Stack (å•å…ƒå·)",
                        type='category', # å¼ºåˆ¶åˆ†ç±»è½´
                        side='bottom'
                    ),
                    
                    yaxis=dict(
                        title="Floor (æ¥¼å±‚)",
                        type='category', # âŒ å…³é”®ï¼šä¸å†æ˜¯ Linearï¼Œè€Œæ˜¯ Category
                        categoryorder='array', # â— å¼ºåˆ¶æŒ‡å®šæ’åºï¼Œé˜²æ­¢ "10" æ’åœ¨ "2" å‰é¢
                        categoryarray=y_category_order, 
                        dtick=1
                    ),
                    
                    plot_bgcolor='white',
                    height=max(500, len(y_category_order) * 30), # åŠ¨æ€é«˜åº¦ï¼šæ¥¼å±‚è¶Šå¤šå›¾è¶Šé«˜
                    width=min(1000, 100 * len(all_stacks) + 200),
                    margin=dict(l=50, r=50, t=60, b=50)
                )

                st.plotly_chart(fig_tower, use_container_width=True, config={
                    'toImageButtonOptions': {'format': 'png', 'height': exp_height, 'width': exp_width, 'scale': exp_scale}
                })
                
                # é¢æ¿
                sold_count = len(sold_df)
                total_count = len(viz_df)
                coverage = (sold_count/total_count*100)
                st.info(f"ğŸ“Š {selected_blk}æ ‹ çœ‹æ¿ï¼šæ¨ç®—æ€»æˆ·æ•° {total_count} | å†å²æˆäº¤ {sold_count} | æ¢æ‰‹ç‡ {coverage:.1f}%")
            else:
                st.warning("æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆé€è§†å›¾")
    else:
        st.warning("CSV ç¼ºå°‘ BLK åˆ—ï¼Œæ— æ³•æ˜¾ç¤ºæ¥¼å®‡é€è§†")